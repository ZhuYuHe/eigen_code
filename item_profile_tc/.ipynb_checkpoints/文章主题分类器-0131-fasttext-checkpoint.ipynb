{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/raid3/home/xueyou/github/simplex\n"
     ]
    }
   ],
   "source": [
    "cd ~/github/simplex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import simplex\n",
    "from simplex import utils\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28362"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_articles = []\n",
    "for filename in tqdm(glob.glob(\"/data/xueyou/fashion/sku/taobao_headline_articles/*_0\")):\n",
    "    for line in open(filename):\n",
    "        tokens = line.strip().split('\\x01')\n",
    "        if len(tokens) == 4:\n",
    "            headline = tokens[1]\n",
    "            category = tokens[2]\n",
    "            body = tokens[3]\n",
    "            hd_articles.append((headline,category,json.loads(body)))\n",
    "len(hd_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'型男': 283,\n",
       "         '头条': 12620,\n",
       "         '居家': 438,\n",
       "         '手机': 3464,\n",
       "         '数码': 2340,\n",
       "         '旅行': 5503,\n",
       "         '母婴': 485,\n",
       "         '美容': 517,\n",
       "         '美搭': 2712})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([c for _,c,_ in hd_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28362/28362 [00:00<00:00, 44519.41it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for _,c,content in tqdm(hd_articles):\n",
    "    text = []\n",
    "    for i,item in enumerate(content):\n",
    "        if i == 1:\n",
    "            continue\n",
    "        if item['type'] == 'para' and item['value'] != '去购买' and 'securityUtil.unescapeHtml' not in item['value']:\n",
    "            text.append(item['value'])\n",
    "    texts.append((c,\"\\n\".join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = open('/data/xueyou/fashion/sku/words/fashion.words.1123.txt').read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(open(\"/tmp/stop_words.txt\").read().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.766 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "for w in words:\n",
    "    jieba.add_word(w,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "split_tokens = \"([，。？！?\\n...])\"\n",
    "\n",
    "def simple_split(text):\n",
    "    for item in re.split(split_tokens, text):\n",
    "        if item:\n",
    "            yield item\n",
    "\n",
    "def tokenize_number(text):\n",
    "    return re.sub(\"\\d+\",'0',text)\n",
    "            \n",
    "def get_sentences(content):\n",
    "    tokens = []\n",
    "    for s in simple_split(content.lower()):\n",
    "        s = re.sub(u'[^\\u4e00-\\u9fa50-9a-zA-Z]+','',s)\n",
    "        if s:\n",
    "            sentence = list([w for w in jieba.cut(s) if w not in stop_words])\n",
    "            tokens.extend(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phone_keywords = [ '手机','全面屏', 'ios11', 'iphone', '华为', '摄像头', 'iphone', '新机', 'mate10', '小米', '手机壳', '一加', 'vivox20', '全面屏手机', 'iphone8',\n",
    " '荣耀', '后置', '魅族', '努比亚', 'note8', '锤子', '前置', '旗舰', '指纹识别', '骁龙', '拍照', '视网膜', 'htcu11', '雷军', '金立', '魅蓝', 'vivo', '机型',\n",
    " '像素', '华为 mate10', '这款 手机', 'oppo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xueyou/.conda/envs/jason_py3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning:NLP backend server not found, use built in functions.\n"
     ]
    }
   ],
   "source": [
    "from simplex.model import KeyWordClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phone_kw = KeyWordClassifier(weighted=False,keywords=phone_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28362it [00:00, 206362.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 手机类别下有些不是手机文章，通过关键词过滤\n",
    "for i,(c,s) in tqdm(enumerate(texts)):\n",
    "    if c == '手机':\n",
    "        if phone_kw.predict(s,method=1)[0] >= 4.0:\n",
    "            continue\n",
    "        else:\n",
    "            texts[i] = (\"头条\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b40de0daeb89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'美搭'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "[t for c,t in texts if c =='美搭'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'型男': 283,\n",
       "         '头条': 13514,\n",
       "         '居家': 438,\n",
       "         '手机': 2570,\n",
       "         '数码': 2340,\n",
       "         '旅行': 5503,\n",
       "         '母婴': 485,\n",
       "         '美容': 517,\n",
       "         '美搭': 2712})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([c for c,_ in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28362/28362 [00:46<00:00, 605.69it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenize_articles = []\n",
    "for c,s in tqdm(texts):\n",
    "    # 头条和旅行文章比较杂，先不处理\n",
    "    if c!='头条' and c!='旅行':\n",
    "        tokens = get_sentences(s)\n",
    "        content = ' '.join(tokens)\n",
    "        tokenize_articles.append((c,content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('手机',\n",
       " '开售 秒 光 高颜值 努比亚 z17s 受欢迎 努比亚 本月 发布 全面屏 2 1 手机 努比亚 z17s 无 边框 全面屏 四摄 光环 加持 下 z17s 首销 网友们 直接 秒 光 今天上午 努比亚 再次 开放 购买 z17s 很快 宣告 售罄 这款 z17s 为啥 会 引起 消费者 高昂 购买 欲望 答案 很 简单 出色 性能 极高 颜值 都 使 鹤立鸡群 骁龙 835 平台 6gb 运存 最 亮眼 屏幕 设计 得益于 无 边框 全面屏 设计 该机 屏 占比 达到 惊人 90 36 全面屏手机 中 独一无二 努比亚 z17s 摄像头 实力 非常 强劲 后置 双 1200 万 像素 摄像头 f1 8 大 光圈 配合 智能 降噪 功能 夜拍 效果 同样 清晰 自主研发 neovision7 0 摄像 引擎 全面 升级 全新 ai 人像 2 0 具有 面部 识别 面部 记忆 智能 边缘 处理 背景 虚化 3d 智能 美颜 像素 级 肤质 增强 技术 人 拍摄 一拍 美 越 拍 越 美 首次 手机 实现 多点 对焦 功能 拥有 25 独立 焦点 摆脱 传统 手机 拍照 对焦 时 常常 出现 对焦 慢失 焦 焦点 错误 问题 强劲 性能 极高 颜值 出众 拍照 之外 努比亚 z17s 2999 元起 售价 相比 全面屏手机 来说 性价比 可谓 相当 出众 颜有 谱 还 不贵 手机 卖 不好 奇怪 没有 买到 朋友 11 月初 z17s 下 一轮 开售 千万 不要错过')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_articles[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9345"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenize_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20903it [00:16, 1299.11it/s]"
     ]
    }
   ],
   "source": [
    "# 先加入随机的微信文章作为其他类别\n",
    "others = []\n",
    "with open(\"/data/xueyou/fashion/sku/weixin_content_2017_10/000000_0\") as f:\n",
    "    for line in tqdm(f):\n",
    "        content = line.strip().split(\"\\x01\")[1]\n",
    "        if len(content) > 100 and random.randint(0,8)==0:\n",
    "            tokens = get_sentences(content)\n",
    "            others.append(('其他',\" \".join(tokens)))\n",
    "        if len(others) == 2000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenize_articles.extend(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenize_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tags,articles = zip(*tokenize_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(articles,tags,test_size=0.1,random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-357f18f3d16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastText\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastText'"
     ]
    }
   ],
   "source": [
    "import fastText as fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"/data/xueyou/fashion/data/category.train.txt\",'w') as out:\n",
    "    for c,text in zip(Y_train,X_train):\n",
    "        text = text + \"\\t__label__\" + c + \"\\n\"\n",
    "        out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 注意，这里的测试数据不要覆盖了\n",
    "with open(\"/data/xueyou/fashion/data/category.test.txt\",'w') as out:\n",
    "    for c,text in zip(Y_test,X_test):\n",
    "        text = text + \"\\t__label__\" + c + \"\\n\"\n",
    "        out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_file_path = '/data/xueyou/fashion/data/category.train.txt'\n",
    "classifier = fasttext.train_supervised(train_file_path,epoch=30,wordNgrams=2,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 0.9444933920704845, 0.9444933920704845)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = \"/data/xueyou/fashion/data/category.test.txt\"\n",
    "classifier.test(path=test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'其他', '型男', '居家', '手机', '数码', '母婴', '美容', '美搭'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verify\n",
    "labels = []\n",
    "txts = []\n",
    "count = 0\n",
    "\n",
    "total_count= 0\n",
    "predict_count = 0\n",
    "predict_true_count = 0\n",
    "\n",
    "for line in open(test_file_path,\"r\") :\n",
    "    labels_right = line.split(\"\\t\")[1].rstrip().replace(\"__label__\",\"\")  \n",
    "    txts.append(line.split(\"\\t\")[0])\n",
    "    labels.append(labels_right)\n",
    "\n",
    "p = classifier.predict(txts)[0]\n",
    "labels_predict =[e[0].replace(\"__label__\",\"\")  for e in p]\n",
    "set(labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         其他      0.904     0.947     0.925       189\n",
      "         型男      0.933     0.903     0.918        31\n",
      "         居家      0.949     0.925     0.937        40\n",
      "         手机      0.961     0.943     0.952       261\n",
      "         数码      0.944     0.919     0.932       259\n",
      "         母婴      0.933     0.933     0.933        45\n",
      "         美容      0.870     0.968     0.916        62\n",
      "         美搭      0.984     0.976     0.980       248\n",
      "\n",
      "avg / total      0.945     0.944     0.945      1135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(labels, labels_predict,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20903it [00:34, 602.95it/s] "
     ]
    }
   ],
   "source": [
    "classifier.save_model(path=\"/data/xueyou/fashion/data/category.fasttext.model.0131.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return \" \".join(get_sentences(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__数码'], ['__label__手机']], array([[ 0.95282727],\n",
       "        [ 1.00001001]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([tokenize_text(texts[23][1]),tokenize_text(texts[90][1])],threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-494c0dec1a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.predict([\" \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28362 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 14/28362 [00:00<03:28, 136.26it/s]\u001b[A\n",
      "  0%|          | 37/28362 [00:00<02:40, 176.37it/s]\u001b[A\n",
      "  0%|          | 62/28362 [00:00<02:22, 198.13it/s]\u001b[A\n",
      "  0%|          | 85/28362 [00:00<02:18, 204.74it/s]\u001b[A\n",
      "  0%|          | 106/28362 [00:00<02:18, 203.61it/s]\u001b[A\n",
      "  0%|          | 126/28362 [00:00<02:21, 200.16it/s]\u001b[A\n",
      "  1%|          | 150/28362 [00:00<02:17, 205.03it/s]\u001b[A\n",
      "  1%|          | 180/28362 [00:00<02:10, 215.91it/s]\u001b[A\n",
      "  1%|          | 204/28362 [00:00<02:09, 217.62it/s]\u001b[A\n",
      "  1%|          | 227/28362 [00:01<02:09, 217.14it/s]\u001b[A\n",
      "  1%|          | 250/28362 [00:01<02:09, 217.91it/s]\u001b[A\n",
      "  1%|          | 277/28362 [00:01<02:06, 222.07it/s]\u001b[A\n",
      "  1%|          | 301/28362 [00:01<02:06, 221.21it/s]\u001b[A\n",
      "  1%|          | 324/28362 [00:01<02:07, 219.07it/s]\u001b[A\n",
      "  1%|          | 346/28362 [00:01<02:08, 218.36it/s]\u001b[A\n",
      "  1%|▏         | 369/28362 [00:01<02:07, 218.72it/s]\u001b[A\n",
      "  1%|▏         | 392/28362 [00:01<02:07, 219.34it/s]\u001b[A\n",
      "  1%|▏         | 415/28362 [00:01<02:08, 217.34it/s]\u001b[A\n",
      "  2%|▏         | 437/28362 [00:02<02:09, 215.67it/s]\u001b[A\n",
      "  2%|▏         | 465/28362 [00:02<02:07, 218.27it/s]\u001b[A\n",
      "  2%|▏         | 491/28362 [00:02<02:06, 219.97it/s]\u001b[A\n",
      "  2%|▏         | 515/28362 [00:02<02:07, 219.06it/s]\u001b[A\n",
      "  2%|▏         | 539/28362 [00:02<02:06, 219.63it/s]\u001b[A\n",
      "  2%|▏         | 562/28362 [00:02<02:07, 218.07it/s]\u001b[A\n",
      "  2%|▏         | 588/28362 [00:02<02:06, 219.62it/s]\u001b[A\n",
      "  2%|▏         | 612/28362 [00:02<02:05, 220.27it/s]\u001b[A\n",
      "  2%|▏         | 636/28362 [00:02<02:05, 220.05it/s]\u001b[A\n",
      "  2%|▏         | 659/28362 [00:02<02:05, 219.89it/s]\u001b[A\n",
      "  2%|▏         | 682/28362 [00:03<02:06, 218.60it/s]\u001b[A\n",
      "  2%|▏         | 704/28362 [00:03<02:06, 218.22it/s]\u001b[A\n",
      "  3%|▎         | 728/28362 [00:03<02:06, 218.83it/s]\u001b[A\n",
      "  3%|▎         | 754/28362 [00:03<02:05, 219.92it/s]\u001b[A\n",
      "  3%|▎         | 777/28362 [00:03<02:05, 219.33it/s]\u001b[A\n",
      "  3%|▎         | 804/28362 [00:03<02:05, 220.34it/s]\u001b[A\n",
      "  3%|▎         | 829/28362 [00:03<02:04, 220.87it/s]\u001b[A\n",
      "  3%|▎         | 853/28362 [00:03<02:04, 220.25it/s]\u001b[A\n",
      "  3%|▎         | 876/28362 [00:03<02:05, 219.66it/s]\u001b[A\n",
      "  3%|▎         | 898/28362 [00:04<02:06, 216.41it/s]\u001b[A\n",
      "  4%|▎         | 1042/28362 [00:04<01:51, 245.21it/s]\u001b[A\n",
      "  4%|▍         | 1099/28362 [00:04<01:51, 244.90it/s]\u001b[A\n",
      "  4%|▍         | 1146/28362 [00:04<01:51, 243.26it/s]\u001b[A\n",
      "  4%|▍         | 1186/28362 [00:04<01:52, 242.33it/s]\u001b[A\n",
      "  4%|▍         | 1220/28362 [00:05<01:51, 242.62it/s]\u001b[A\n",
      "  4%|▍         | 1252/28362 [00:05<01:52, 242.05it/s]\u001b[A\n",
      "  5%|▍         | 1281/28362 [00:05<01:51, 241.99it/s]\u001b[A\n",
      "  5%|▍         | 1309/28362 [00:05<01:51, 242.06it/s]\u001b[A\n",
      "  5%|▍         | 1337/28362 [00:05<01:51, 242.62it/s]\u001b[A\n",
      "  5%|▍         | 1364/28362 [00:05<01:51, 242.64it/s]\u001b[A\n",
      "  5%|▍         | 1394/28362 [00:05<01:50, 243.57it/s]\u001b[A\n",
      "  5%|▌         | 1428/28362 [00:05<01:49, 245.01it/s]\u001b[A\n",
      "  5%|▌         | 1457/28362 [00:05<01:49, 245.55it/s]\u001b[A\n",
      "  5%|▌         | 1488/28362 [00:06<01:48, 246.58it/s]\u001b[A\n",
      "  5%|▌         | 1518/28362 [00:06<01:48, 246.83it/s]\u001b[A\n",
      "  5%|▌         | 1548/28362 [00:06<01:48, 247.49it/s]\u001b[A\n",
      "  6%|▌         | 1577/28362 [00:06<01:48, 246.91it/s]\u001b[A\n",
      "  6%|▌         | 1604/28362 [00:06<01:49, 245.35it/s]\u001b[A\n",
      "  6%|▌         | 1632/28362 [00:06<01:48, 245.79it/s]\u001b[A\n",
      "  6%|▌         | 1660/28362 [00:06<01:48, 246.13it/s]\u001b[A\n",
      "  6%|▌         | 1686/28362 [00:06<01:48, 246.26it/s]\u001b[A\n",
      "  6%|▌         | 1712/28362 [00:06<01:48, 245.94it/s]\u001b[A\n",
      "  6%|▌         | 1737/28362 [00:07<01:48, 245.78it/s]\u001b[A\n",
      "  6%|▌         | 1762/28362 [00:07<01:48, 245.66it/s]\u001b[A\n",
      "  6%|▋         | 1787/28362 [00:07<01:48, 245.12it/s]\u001b[A\n",
      "  6%|▋         | 1811/28362 [00:07<01:48, 244.89it/s]\u001b[A\n",
      "  6%|▋         | 1843/28362 [00:07<01:47, 245.86it/s]\u001b[A\n",
      "  7%|▋         | 1869/28362 [00:07<01:48, 245.29it/s]\u001b[A\n",
      "  7%|▋         | 1894/28362 [00:07<01:47, 245.10it/s]\u001b[A\n",
      "  7%|▋         | 1918/28362 [00:07<01:48, 244.76it/s]\u001b[A\n",
      "  7%|▋         | 1943/28362 [00:07<01:47, 244.83it/s]\u001b[A\n",
      "  7%|▋         | 1967/28362 [00:08<01:47, 244.49it/s]\u001b[A\n",
      "  7%|▋         | 1991/28362 [00:08<01:47, 244.20it/s]\u001b[A\n",
      "  7%|▋         | 2015/28362 [00:08<01:48, 243.79it/s]\u001b[A\n",
      "  7%|▋         | 2038/28362 [00:08<01:48, 243.53it/s]\u001b[A\n",
      "  7%|▋         | 2061/28362 [00:08<01:48, 243.37it/s]\u001b[A\n",
      "  7%|▋         | 2089/28362 [00:08<01:47, 243.78it/s]\u001b[A\n",
      "  7%|▋         | 2114/28362 [00:08<01:47, 243.18it/s]\u001b[A\n",
      "  8%|▊         | 2141/28362 [00:08<01:47, 243.48it/s]\u001b[A\n",
      "  8%|▊         | 2166/28362 [00:08<01:47, 243.34it/s]\u001b[A\n",
      "  8%|▊         | 2193/28362 [00:09<01:47, 243.61it/s]\u001b[A\n",
      "  8%|▊         | 2218/28362 [00:09<01:47, 243.64it/s]\u001b[A\n",
      "  8%|▊         | 2243/28362 [00:09<01:47, 243.37it/s]\u001b[A\n",
      "  8%|▊         | 2270/28362 [00:09<01:47, 243.58it/s]\u001b[A\n",
      "  8%|▊         | 2295/28362 [00:09<01:47, 242.95it/s]Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xueyou/.conda/envs/jason_py3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/xueyou/.conda/envs/jason_py3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/xueyou/.conda/envs/jason_py3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 28362/28362 [01:27<00:00, 323.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tt_articles = []\n",
    "count = Counter()\n",
    "batch = []\n",
    "\n",
    "# 重新分类头条和旅行的文章\n",
    "for c,text in tqdm(texts):\n",
    "    if c == '头条' or c=='旅行':\n",
    "        batch.append(tokenize_text(text))\n",
    "        if len(batch)==100:\n",
    "            for i,predict in enumerate(classifier.predict(batch,threshold=0.8)[0]):\n",
    "                if len(predict) == 0:\n",
    "                    continue\n",
    "                lable = predict[0].replace(\"__label__\",\"\")\n",
    "                \n",
    "                count[lable] += 1\n",
    "                tt_articles.append((lable,batch[i]))\n",
    "            batch = []\n",
    "    \n",
    "if len(batch)>0:\n",
    "    for i,predict in enumerate(classifier.predict(batch)[0]):\n",
    "        lable = predict[0].replace(\"__label__\",\"\")\n",
    "        count[lable] += 1\n",
    "        tt_articles.append((lable,batch[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'其他': 3553,\n",
       "         '型男': 911,\n",
       "         '居家': 1333,\n",
       "         '手机': 1451,\n",
       "         '数码': 1503,\n",
       "         '母婴': 1230,\n",
       "         '美容': 1918,\n",
       "         '美搭': 2588})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14487"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = list(zip(Y_train,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10210"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.extend(tt_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14487"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tt_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24697"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_count = Counter()\n",
    "for c,_ in train:\n",
    "    train_count[c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'其他': 5364,\n",
       "         '型男': 1163,\n",
       "         '居家': 1731,\n",
       "         '手机': 3760,\n",
       "         '数码': 3584,\n",
       "         '母婴': 1670,\n",
       "         '美容': 2373,\n",
       "         '美搭': 5052})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"/data/xueyou/fashion/data/category.train.more.txt\",'w') as out:\n",
    "    for c,text in train:\n",
    "        text = text + \"\\t__label__\" + c + \"\\n\"\n",
    "        out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_supervised in module fastText.FastText:\n",
      "\n",
      "train_supervised(input, lr=0.1, dim=100, ws=5, epoch=5, minCount=1, minCountLabel=0, minn=0, maxn=0, neg=5, wordNgrams=1, loss='softmax', bucket=2000000, thread=12, lrUpdateRate=100, t=0.0001, label='__label__', verbose=2, pretrainedVectors='')\n",
      "    Train a supervised model and return a model object.\n",
      "    \n",
      "    input must be a filepath. The input text does not need to be tokenized\n",
      "    as per the tokenize function, but it must be preprocessed and encoded\n",
      "    as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "    \n",
      "    The input file must must contain at least one label per line. For an\n",
      "    example consult the example datasets which are part of the fastText\n",
      "    repository such as the dataset pulled by classification-example.sh.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.train_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train with epoch 25, lr 0.4, dim 80, ws 5\n",
      "found best val 0.9356828193832599 with params: epoch - 25, lr - 0.4, dim - 80, ws - 5 \n",
      "train with epoch 25, lr 0.4, dim 80, ws 8\n",
      "train with epoch 25, lr 0.4, dim 80, ws 10\n",
      "train with epoch 25, lr 0.4, dim 100, ws 5\n",
      "train with epoch 25, lr 0.4, dim 100, ws 8\n",
      "train with epoch 25, lr 0.4, dim 100, ws 10\n",
      "train with epoch 25, lr 0.4, dim 120, ws 5\n",
      "train with epoch 25, lr 0.4, dim 120, ws 8\n",
      "train with epoch 25, lr 0.4, dim 120, ws 10\n",
      "train with epoch 25, lr 0.4, dim 150, ws 5\n",
      "train with epoch 25, lr 0.4, dim 150, ws 8\n",
      "train with epoch 25, lr 0.4, dim 150, ws 10\n",
      "train with epoch 25, lr 0.6, dim 80, ws 5\n",
      "found best val 0.9365638766519824 with params: epoch - 25, lr - 0.6, dim - 80, ws - 5 \n",
      "train with epoch 25, lr 0.6, dim 80, ws 8\n",
      "train with epoch 25, lr 0.6, dim 80, ws 10\n",
      "train with epoch 25, lr 0.6, dim 100, ws 5\n",
      "found best val 0.9383259911894273 with params: epoch - 25, lr - 0.6, dim - 100, ws - 5 \n",
      "train with epoch 25, lr 0.6, dim 100, ws 8\n",
      "train with epoch 25, lr 0.6, dim 100, ws 10\n",
      "found best val 0.9392070484581497 with params: epoch - 25, lr - 0.6, dim - 100, ws - 10 \n",
      "train with epoch 25, lr 0.6, dim 120, ws 5\n",
      "train with epoch 25, lr 0.6, dim 120, ws 8\n",
      "train with epoch 25, lr 0.6, dim 120, ws 10\n",
      "train with epoch 25, lr 0.6, dim 150, ws 5\n",
      "train with epoch 25, lr 0.6, dim 150, ws 8\n",
      "train with epoch 25, lr 0.6, dim 150, ws 10\n",
      "train with epoch 25, lr 0.8, dim 80, ws 5\n",
      "train with epoch 25, lr 0.8, dim 80, ws 8\n",
      "train with epoch 25, lr 0.8, dim 80, ws 10\n",
      "train with epoch 25, lr 0.8, dim 100, ws 5\n",
      "train with epoch 25, lr 0.8, dim 100, ws 8\n",
      "train with epoch 25, lr 0.8, dim 100, ws 10\n",
      "train with epoch 25, lr 0.8, dim 120, ws 5\n",
      "found best val 0.9409691629955947 with params: epoch - 25, lr - 0.8, dim - 120, ws - 5 \n",
      "train with epoch 25, lr 0.8, dim 120, ws 8\n",
      "train with epoch 25, lr 0.8, dim 120, ws 10\n",
      "train with epoch 25, lr 0.8, dim 150, ws 5\n",
      "train with epoch 25, lr 0.8, dim 150, ws 8\n",
      "train with epoch 25, lr 0.8, dim 150, ws 10\n",
      "train with epoch 25, lr 1.0, dim 80, ws 5\n",
      "train with epoch 25, lr 1.0, dim 80, ws 8\n",
      "train with epoch 25, lr 1.0, dim 80, ws 10\n",
      "train with epoch 25, lr 1.0, dim 100, ws 5\n",
      "train with epoch 25, lr 1.0, dim 100, ws 8\n",
      "train with epoch 25, lr 1.0, dim 100, ws 10\n",
      "train with epoch 25, lr 1.0, dim 120, ws 5\n",
      "train with epoch 25, lr 1.0, dim 120, ws 8\n",
      "train with epoch 25, lr 1.0, dim 120, ws 10\n",
      "train with epoch 25, lr 1.0, dim 150, ws 5\n",
      "train with epoch 25, lr 1.0, dim 150, ws 8\n",
      "train with epoch 25, lr 1.0, dim 150, ws 10\n",
      "train with epoch 30, lr 0.4, dim 80, ws 5\n",
      "train with epoch 30, lr 0.4, dim 80, ws 8\n",
      "train with epoch 30, lr 0.4, dim 80, ws 10\n",
      "train with epoch 30, lr 0.4, dim 100, ws 5\n",
      "train with epoch 30, lr 0.4, dim 100, ws 8\n",
      "train with epoch 30, lr 0.4, dim 100, ws 10\n",
      "train with epoch 30, lr 0.4, dim 120, ws 5\n",
      "train with epoch 30, lr 0.4, dim 120, ws 8\n",
      "train with epoch 30, lr 0.4, dim 120, ws 10\n",
      "train with epoch 30, lr 0.4, dim 150, ws 5\n",
      "train with epoch 30, lr 0.4, dim 150, ws 8\n",
      "train with epoch 30, lr 0.4, dim 150, ws 10\n",
      "train with epoch 30, lr 0.6, dim 80, ws 5\n",
      "train with epoch 30, lr 0.6, dim 80, ws 8\n",
      "train with epoch 30, lr 0.6, dim 80, ws 10\n",
      "train with epoch 30, lr 0.6, dim 100, ws 5\n",
      "train with epoch 30, lr 0.6, dim 100, ws 8\n",
      "train with epoch 30, lr 0.6, dim 100, ws 10\n",
      "train with epoch 30, lr 0.6, dim 120, ws 5\n",
      "train with epoch 30, lr 0.6, dim 120, ws 8\n",
      "train with epoch 30, lr 0.6, dim 120, ws 10\n",
      "train with epoch 30, lr 0.6, dim 150, ws 5\n",
      "train with epoch 30, lr 0.6, dim 150, ws 8\n",
      "train with epoch 30, lr 0.6, dim 150, ws 10\n",
      "train with epoch 30, lr 0.8, dim 80, ws 5\n",
      "train with epoch 30, lr 0.8, dim 80, ws 8\n",
      "train with epoch 30, lr 0.8, dim 80, ws 10\n",
      "train with epoch 30, lr 0.8, dim 100, ws 5\n",
      "train with epoch 30, lr 0.8, dim 100, ws 8\n",
      "train with epoch 30, lr 0.8, dim 100, ws 10\n",
      "train with epoch 30, lr 0.8, dim 120, ws 5\n",
      "train with epoch 30, lr 0.8, dim 120, ws 8\n",
      "train with epoch 30, lr 0.8, dim 120, ws 10\n",
      "train with epoch 30, lr 0.8, dim 150, ws 5\n",
      "train with epoch 30, lr 0.8, dim 150, ws 8\n",
      "train with epoch 30, lr 0.8, dim 150, ws 10\n",
      "train with epoch 30, lr 1.0, dim 80, ws 5\n",
      "train with epoch 30, lr 1.0, dim 80, ws 8\n",
      "train with epoch 30, lr 1.0, dim 80, ws 10\n",
      "train with epoch 30, lr 1.0, dim 100, ws 5\n",
      "train with epoch 30, lr 1.0, dim 100, ws 8\n",
      "train with epoch 30, lr 1.0, dim 100, ws 10\n",
      "train with epoch 30, lr 1.0, dim 120, ws 5\n",
      "train with epoch 30, lr 1.0, dim 120, ws 8\n",
      "train with epoch 30, lr 1.0, dim 120, ws 10\n",
      "train with epoch 30, lr 1.0, dim 150, ws 5\n",
      "train with epoch 30, lr 1.0, dim 150, ws 8\n",
      "train with epoch 30, lr 1.0, dim 150, ws 10\n",
      "train with epoch 35, lr 0.4, dim 80, ws 5\n",
      "train with epoch 35, lr 0.4, dim 80, ws 8\n",
      "train with epoch 35, lr 0.4, dim 80, ws 10\n",
      "train with epoch 35, lr 0.4, dim 100, ws 5\n",
      "train with epoch 35, lr 0.4, dim 100, ws 8\n",
      "train with epoch 35, lr 0.4, dim 100, ws 10\n",
      "train with epoch 35, lr 0.4, dim 120, ws 5\n",
      "train with epoch 35, lr 0.4, dim 120, ws 8\n",
      "train with epoch 35, lr 0.4, dim 120, ws 10\n",
      "train with epoch 35, lr 0.4, dim 150, ws 5\n",
      "train with epoch 35, lr 0.4, dim 150, ws 8\n",
      "train with epoch 35, lr 0.4, dim 150, ws 10\n",
      "train with epoch 35, lr 0.6, dim 80, ws 5\n",
      "train with epoch 35, lr 0.6, dim 80, ws 8\n",
      "train with epoch 35, lr 0.6, dim 80, ws 10\n",
      "train with epoch 35, lr 0.6, dim 100, ws 5\n",
      "train with epoch 35, lr 0.6, dim 100, ws 8\n",
      "train with epoch 35, lr 0.6, dim 100, ws 10\n",
      "train with epoch 35, lr 0.6, dim 120, ws 5\n",
      "train with epoch 35, lr 0.6, dim 120, ws 8\n",
      "train with epoch 35, lr 0.6, dim 120, ws 10\n",
      "train with epoch 35, lr 0.6, dim 150, ws 5\n",
      "train with epoch 35, lr 0.6, dim 150, ws 8\n",
      "train with epoch 35, lr 0.6, dim 150, ws 10\n",
      "train with epoch 35, lr 0.8, dim 80, ws 5\n",
      "train with epoch 35, lr 0.8, dim 80, ws 8\n",
      "train with epoch 35, lr 0.8, dim 80, ws 10\n",
      "train with epoch 35, lr 0.8, dim 100, ws 5\n",
      "train with epoch 35, lr 0.8, dim 100, ws 8\n",
      "train with epoch 35, lr 0.8, dim 100, ws 10\n",
      "train with epoch 35, lr 0.8, dim 120, ws 5\n",
      "train with epoch 35, lr 0.8, dim 120, ws 8\n",
      "train with epoch 35, lr 0.8, dim 120, ws 10\n",
      "train with epoch 35, lr 0.8, dim 150, ws 5\n",
      "train with epoch 35, lr 0.8, dim 150, ws 8\n",
      "train with epoch 35, lr 0.8, dim 150, ws 10\n",
      "train with epoch 35, lr 1.0, dim 80, ws 5\n",
      "train with epoch 35, lr 1.0, dim 80, ws 8\n",
      "train with epoch 35, lr 1.0, dim 80, ws 10\n",
      "train with epoch 35, lr 1.0, dim 100, ws 5\n",
      "train with epoch 35, lr 1.0, dim 100, ws 8\n",
      "train with epoch 35, lr 1.0, dim 100, ws 10\n",
      "train with epoch 35, lr 1.0, dim 120, ws 5\n",
      "train with epoch 35, lr 1.0, dim 120, ws 8\n",
      "train with epoch 35, lr 1.0, dim 120, ws 10\n",
      "train with epoch 35, lr 1.0, dim 150, ws 5\n",
      "train with epoch 35, lr 1.0, dim 150, ws 8\n",
      "train with epoch 35, lr 1.0, dim 150, ws 10\n",
      "train with epoch 40, lr 0.4, dim 80, ws 5\n",
      "train with epoch 40, lr 0.4, dim 80, ws 8\n",
      "train with epoch 40, lr 0.4, dim 80, ws 10\n",
      "train with epoch 40, lr 0.4, dim 100, ws 5\n",
      "train with epoch 40, lr 0.4, dim 100, ws 8\n",
      "train with epoch 40, lr 0.4, dim 100, ws 10\n",
      "train with epoch 40, lr 0.4, dim 120, ws 5\n",
      "train with epoch 40, lr 0.4, dim 120, ws 8\n",
      "train with epoch 40, lr 0.4, dim 120, ws 10\n",
      "train with epoch 40, lr 0.4, dim 150, ws 5\n",
      "train with epoch 40, lr 0.4, dim 150, ws 8\n",
      "train with epoch 40, lr 0.4, dim 150, ws 10\n",
      "train with epoch 40, lr 0.6, dim 80, ws 5\n",
      "train with epoch 40, lr 0.6, dim 80, ws 8\n",
      "train with epoch 40, lr 0.6, dim 80, ws 10\n",
      "train with epoch 40, lr 0.6, dim 100, ws 5\n",
      "train with epoch 40, lr 0.6, dim 100, ws 8\n",
      "train with epoch 40, lr 0.6, dim 100, ws 10\n",
      "train with epoch 40, lr 0.6, dim 120, ws 5\n",
      "train with epoch 40, lr 0.6, dim 120, ws 8\n",
      "train with epoch 40, lr 0.6, dim 120, ws 10\n",
      "train with epoch 40, lr 0.6, dim 150, ws 5\n",
      "train with epoch 40, lr 0.6, dim 150, ws 8\n",
      "train with epoch 40, lr 0.6, dim 150, ws 10\n",
      "train with epoch 40, lr 0.8, dim 80, ws 5\n",
      "train with epoch 40, lr 0.8, dim 80, ws 8\n",
      "train with epoch 40, lr 0.8, dim 80, ws 10\n",
      "train with epoch 40, lr 0.8, dim 100, ws 5\n",
      "train with epoch 40, lr 0.8, dim 100, ws 8\n",
      "train with epoch 40, lr 0.8, dim 100, ws 10\n",
      "train with epoch 40, lr 0.8, dim 120, ws 5\n",
      "train with epoch 40, lr 0.8, dim 120, ws 8\n",
      "train with epoch 40, lr 0.8, dim 120, ws 10\n",
      "train with epoch 40, lr 0.8, dim 150, ws 5\n",
      "train with epoch 40, lr 0.8, dim 150, ws 8\n",
      "train with epoch 40, lr 0.8, dim 150, ws 10\n",
      "train with epoch 40, lr 1.0, dim 80, ws 5\n",
      "train with epoch 40, lr 1.0, dim 80, ws 8\n",
      "train with epoch 40, lr 1.0, dim 80, ws 10\n",
      "train with epoch 40, lr 1.0, dim 100, ws 5\n",
      "train with epoch 40, lr 1.0, dim 100, ws 8\n",
      "train with epoch 40, lr 1.0, dim 100, ws 10\n",
      "train with epoch 40, lr 1.0, dim 120, ws 5\n",
      "train with epoch 40, lr 1.0, dim 120, ws 8\n",
      "train with epoch 40, lr 1.0, dim 120, ws 10\n",
      "train with epoch 40, lr 1.0, dim 150, ws 5\n",
      "train with epoch 40, lr 1.0, dim 150, ws 8\n",
      "train with epoch 40, lr 1.0, dim 150, ws 10\n"
     ]
    }
   ],
   "source": [
    "train_file_path = '/data/xueyou/fashion/data/category.train.more.txt'\n",
    "best_model = None\n",
    "best_test = -1000\n",
    "for epoch in [25,30,35,40]:\n",
    "    for lr in [0.4, 0.6, 0.8, 1.0]:\n",
    "        for dim in [80,100,120,150]:\n",
    "            for ws in [5,8,10]:\n",
    "                print(\"train with epoch {}, lr {}, dim {}, ws {}\".format(epoch,lr,dim,ws))\n",
    "                classifier_v2 = fasttext.train_supervised(train_file_path,epoch=epoch,wordNgrams=2,lr=lr,dim=dim,ws=ws)\n",
    "                val = classifier_v2.test(path=test_file_path)[1]\n",
    "                if val > best_test:\n",
    "                    print(\"found best val {} with params: epoch - {}, lr - {}, dim - {}, ws - {} \".format(val,epoch,lr,dim,ws))\n",
    "                    best_test = val\n",
    "                    best_model = classifier_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 0.9409691629955947, 0.9409691629955947)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = \"/data/xueyou/fashion/data/category.test.txt\"\n",
    "best_model.test(path=test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'其他', '型男', '居家', '手机', '数码', '母婴', '美容', '美搭'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verify\n",
    "labels = []\n",
    "txts = []\n",
    "\n",
    "for line in open(test_file_path,\"r\") :\n",
    "    labels_right = line.split(\"\\t\")[1].rstrip().replace(\"__label__\",\"\")  \n",
    "    txts.append(line.split(\"\\t\")[0])\n",
    "    labels.append(labels_right)\n",
    "\n",
    "p = best_model.predict(txts)[0]\n",
    "labels_predict =[e[0].replace(\"__label__\",\"\")  for e in p]\n",
    "set(labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         其他      0.895     0.947     0.920       189\n",
      "         型男      0.931     0.871     0.900        31\n",
      "         居家      0.925     0.925     0.925        40\n",
      "         手机      0.965     0.946     0.956       261\n",
      "         数码      0.948     0.915     0.931       259\n",
      "         母婴      0.909     0.889     0.899        45\n",
      "         美容      0.855     0.952     0.901        62\n",
      "         美搭      0.980     0.976     0.978       248\n",
      "\n",
      "avg / total      0.942     0.941     0.941      1135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels, labels_predict,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_model.save_model(\"/data/xueyou/fashion/data/category.fasttext.model.0201.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import random\n",
    "more_train_data = []\n",
    "other = []\n",
    "count = Counter()\n",
    "cnt = 0\n",
    "\n",
    "for fname in glob(\"/data/xueyou/fashion/sku/weixin_content_2017_10/*_0\"):\n",
    "    with open(fname) as f:\n",
    "        print(\"process\",fname)\n",
    "        for line in tqdm(f):\n",
    "            tokens = line.strip().split(\"\\x01\")\n",
    "            if len(tokens) == 2:\n",
    "                content = tokens[1]\n",
    "                if len(content) > 100:\n",
    "                    cnt += 1\n",
    "                    content = tokenize_text(content)\n",
    "                    label = classifier.predict([content])[0][0][0].replace(\"__label__\",\"\")\n",
    "                    count[label] += 1\n",
    "                    if label != '其他':\n",
    "                        more_train_data.append((label,content))\n",
    "                    elif len(other) <= 8000:\n",
    "                        if random.randint(0,100) == 0:\n",
    "                            other.append((label,content))\n",
    "'''\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fashion_web_articles = pickle.load(open('/data/xueyou/fashion/sku/articles/fashion_web_articles.1122.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98695"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fashion_web_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:34<00:00, 146.29it/s]\n"
     ]
    }
   ],
   "source": [
    "fashion_web_filter = []\n",
    "fashion_web_count = Counter()\n",
    "for item in tqdm(fashion_web_articles[:5000]):\n",
    "    content = item['content']\n",
    "    if len(content) > 100:\n",
    "        text = tokenize_text(content)\n",
    "        label = best_model.predict([text])[0][0][0].replace(\"__label__\",\"\")\n",
    "        fashion_web_count[label] += 1\n",
    "        fashion_web_filter.append((label,content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'其他': 3065,\n",
       "         '型男': 184,\n",
       "         '居家': 32,\n",
       "         '手机': 51,\n",
       "         '数码': 219,\n",
       "         '母婴': 23,\n",
       "         '美容': 604,\n",
       "         '美搭': 657})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_web_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 - 3065 - 63.39193381592554\n",
      "型男 - 184 - 3.805584281282316\n",
      "数码 - 219 - 4.52947259565667\n",
      "美搭 - 657 - 13.58841778697001\n",
      "母婴 - 23 - 0.4756980351602895\n",
      "美容 - 604 - 12.492244053774561\n",
      "居家 - 32 - 0.6618407445708376\n",
      "手机 - 51 - 1.0548086866597723\n"
     ]
    }
   ],
   "source": [
    "fcnt = sum(fashion_web_count.values())\n",
    "for k,v in fashion_web_count.items():\n",
    "    print(k,v,v/fcnt*100,sep=' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('其他',\n",
       "  '\\n1 爱情与亲情，难以左右逢源1 回顶部 \\n点击图片进入下一页>> \\n一个女孩找我，对我说：姐姐，你能帮我写篇文，以祭奠我逝去的爱情吗?我欣然应允。女孩便将她2年的爱情简短地向我做了描述。女孩的故事，和所有被父母棒打鸳鸯的桥段一样。自由 恋爱 ，男孩比女孩大六岁;这段 感情 遭到男孩父母的极力反对，男孩用两年的时间坚守自己的爱情，劝说父母。终于峰回路转，原定今年三月 结婚 。 \\n拍完婚纱照之后，男孩的父母就女方将来的嫁妆问题，提出了各种的要求。婚期就这样被暂时搁置了;没想到，这一搁置，最终迎来的不是有 情人 终成眷属，而是两年多的感情，分道扬镳。男孩提出的 分手 理由是：我突然发觉父母都老了，我应该为他们而活着。女孩无奈接受了现实。但她越想越觉得不甘心，她觉得如果是两个人的感情出现了问题的话，那么她心甘情愿接受。现在，是心爱的人选择了 亲情 ，而不惜背弃他们的爱情。女孩说，她很不舍，更不知道究竟是谁的错?现在，只想让我能帮她写篇文，就当是对这段感情的纪念。 \\n点击图片进入下一页>> \\n受人之托，诚惶诚恐之余，自当尽全力去修复一段感情对一个女孩所带来的创伤，如果，我的文字有这样的力量与功效的话。我反复思考了一晚上，关于爱情与亲情狭路相逢，谁是胜者?众所周知，爱情和亲情是截然不同的两种 情感 ，但有爱情的地方，注定了要面临亲情的挑战。无数爱情，因为亲情的堵截而留下遗憾，亦有无数亲情，因为爱情的介入，而乱了分寸，为何爱情和亲情就不能左右逢源呢? \\n我们能怪那些因为亲情而放弃爱情的人吗?不能，因为爱情是一首歌，我们可以随意唱出各种的旋律，而亲情是一本厚重的书，隐隐中注定了你要用一生去品读，那种厚重是需要回报的。男孩说突然发现父母都老了，现在应该为父母而活着。我试着将这句话当成是一个冠冕的分手理由，以一个旁观者的立场去揣摩男孩为何在苦苦坚守了两年之后，却突然选择放弃;是他真的累了吗，因为介于爱情和亲情之间已经心力交瘁了吗? \\n2 爱情与亲情，难以左右逢源2 回顶部 \\n点击图片进入下一页>> \\n不可否认，不管是谁一旦坠入 亲情 与爱情的夹击中，都会精疲力尽;亲情，爱情， 友情 ，是我们生命中的三根精神支柱，不管哪一根断裂都将让我们的 情感 世界倾斜。我相信男孩的痛苦不亚于女孩，我们经常会听到这么一个问题：老婆和老妈同时掉入水中，应该先救谁?这个问题让无数男人为难。前不久，现实中真实上演了这一幕，最终，儿子因为就近先救老婆，而遭到父亲的不满。男孩当时所面临的应该就是相同的场景，他牺牲自己的爱情，去捍卫亲情，何尝不是一种无奈。 \\n女孩说，和他生活一辈子的人是我，又不是他父母。没错，父母不可能陪着儿女一辈子，总会先于儿女离开这个世界，但一个无视亲情的人，娶了媳妇忘了娘的男人，你又如何安心将自己的一生交托于他呢?爱情和亲情是两种不同的情感，不应该放在一个天平上来衡量两者之间的比重。很多美好的姻缘最终之所以会被亲情所摧毁，便是如此。而所有的家庭伦理剧，无不围绕着这个主题;要知道亲情和爱情之间终归难以权衡，厚此薄彼都并非过错;要知道没有永远的爱情，只有不变的亲情。 \\n点击图片进入下一页>> \\n其实，在亲情与爱情的博弈中，真的没有最后的赢家;亲情和爱情就像是把双刃剑，总有人会受到伤害。父母用亲情捆绑儿女的个人幸福，理由是为了儿女好;最终往往造成对儿女的一种伤害。而儿女打出爱情牌，挑战亲情的结果，伤害了父母的同时，自己未必就真的能够幸福。都说没有拧得过子女的父母，那是亲情在成全爱情，而今，是爱情给亲情让步，一种回报的背后，牺牲的是自己。亲情和爱情很多时候难以左右逢源，而是顾此失彼。 \\n我想对女孩说，他的父母不认可你，不是因为你不够好，而是他们觉得自己的儿子更加优秀。那些败给亲情的爱情，并非就是最后的输家，不被父母祝福的爱情，将面临着巨大的现实挑战， 婆媳 之战之所以打了千百年，很大程度上就是爱情与亲情的另一种较量与博弈，谁都不肯向谁低头;那些和谐的 婆媳关系 ，背后其实都是相互的迁就与包容，一个在婚前无法包容你的，强势的婆婆，在婚后你必将要更加放低自己，沦为一个受气包，何必委曲求全呢。皆大欢喜的结局，是需要付出巨大的艰辛与代价，需要足够强大的爱情力量才得以支撑。 \\n3 爱情与亲情，难以左右逢源3 回顶部 \\n点击图片进入下一页>> \\n有时候，失去也是另一种得到。每个人的一生都不可能只遇到一次爱情;一段爱情因为客观因素而终结，自然会格外令人不舍，但缘起缘灭有时就是一种定数，一段 感情 的结束，预示着是另一段缘份的开始;好女孩不愁遇不到好姻缘;父母虽然不该包办你的幸福，但越过父母而获得的幸福，未必就是最好的归宿。梁山伯与祝英台，罗密欧与朱丽叶，那是属于文艺作品里的凄婉，现实不需要那样悲壮的爱情。收拾心情，说不定下一段爱情就在转角处。记住，眼泪不是对一段感情的祭奠，遗忘才是。送上喜欢的一首歌，爱自己。 （图片来源：华盖）'),\n",
       " ('其他',\n",
       "  '\\n1 回顶部 \\n生活节奏这么快，脱离校园后你的朋友圈是不是也被各种秀逼格环绕？不知不觉已忘当年初心，翻回去看看之前的作文和日记是不是也觉得自己那会儿蛮有思想的？让我们休闲时光换下犀利派的西装皮裤，变身背带控再年轻一把吧！ \\n点击图片进入下一页>> \\n巧穿背带让我们再年轻一把！ \\n点击图片进入下一页>> \\n就算在潮人中间，这背带裤也是能玩出花的减龄单品，自带青葱校园属性，想卖萌穿上她就对喽~ \\n点击图片进入下一页>> \\n今天我们来介绍几套适合日系妹子的通勤穿搭，这种低胸背带裙往往都是和衬衫、高领衫成套出现，搭配高筒袜也很可爱。 \\n2 回顶部 \\n点击图片进入下一页>> \\n如果你想更IN一点，拉风帽子和包包能成功为你加分，根据色彩随心配，自由度超高！ \\n3 回顶部 \\n点击图片进入下一页>> \\n黑色的背带裤更偏熟龄，如果你想嫩出花儿色彩搭配上就要忌酒红、军绿这样的增龄色彩，简单的黑白条纹单品也需要你选择得当，比如7分袖的罩衫就会比紧身打底衫看着可爱的多。 \\n4 回顶部 \\n点击图片进入下一页>> \\n背带裙搭配卫衣也是不错的选择，元气女都这么穿~ \\n5 回顶部 \\n点击图片进入下一页>> \\n阔腿的拉绒背带裤很难hold住，不是一般显胖啊…这里用紧身的打底衫打造出了修身效果，是不是也很可爱~ \\n6 回顶部 \\n点击图片进入下一页>> \\n背带直筒裙的搭配多种多样，你可以内搭毛衫、宽松卫衣、高领衫，大感觉都不会跑偏，想增加点玩味而不是乖巧的感觉你可以来双Converse，街头风瞬起~ \\n7 回顶部 \\n点击图片进入下一页>> \\n搭配方案推荐：背带裙+卫衣+三叶草 \\n8 回顶部 \\n点击图片进入下一页>> \\n背带裙+卫衣+搭扣皮鞋 \\n9 回顶部 \\n点击图片进入下一页>> \\n格子衫+背带裙+帆布鞋 \\n10 回顶部 \\n点击图片进入下一页>> \\nTee+背带裙+板鞋 \\n11 回顶部 \\n点击图片进入下一页>> \\n高领衫+背带裙+坡跟鞋 \\n12 回顶部 \\n点击图片进入下一页>> \\n针织衫+背带裙+三叶草 \\n13 回顶部 \\n点击图片进入下一页>> \\n高领衫+背带裙+帆布鞋 \\n14 回顶部 \\n点击图片进入下一页>> \\n皮夹克+背带裤+板鞋'),\n",
       " ('其他',\n",
       "  '\\n1 口臭是什么原因？ 回顶部 \\n近期一大波别人家的老公在朋友圈、微博等社交网络刷屏，在这个春暖花开的季节，撩汉必备的招数可不就是清新口气嘛。即便衣着得体、举止洒脱，一旦张口时传出不雅异味，也会让人皱眉败兴并进而对之产生反感。之所以引起 口臭 ，往往与人的身体 健康状况 及 口腔卫生 有着密切关系。口腔唾液的生化成分、酸碱度、杀菌功效、分泌量等皆会受到身体内外环境的影响而发生变化。为了让自己在公众场合的形象风采不留一丝缺憾，为了更好地撩汉，不妨让我们一起来了解一下口臭的成因及对付它的积极办法吧。 \\n口腔异味 也称为口气或口臭。要想 口气清新 就必须清楚引发口腔异味的原因。口腔异味分为病理性、非病理性两大类。非病理性口腔异味可因吸烟、饮酒、喝咖啡以及经常吃葱、蒜、韭菜等 辛辣 刺激 食品 导致。 \\n专家组在口腔异味严重的患者中发现一种普遍现象，就是他们牙根和牙龈接触的缝隙中，普遍存在硫化物，而硫化物是很臭的，通常有机 营养 含量越高的物质，在腐化后或被人体消化吸收后剩余的残渣物都能产生含量很高的硫化物(例如人类的粪便中就含有大量硫化物)。 \\n口腔牙根处存在的这种硫化物，基本可以断定其存在原因是口腔超常消化功能所致。 \\n2 七种食物易造成口臭 你中招没? 回顶部 \\n七种 食物 易造成 口臭 你中招没? \\n1.酒。生活中，酗酒后的人身上总是伴随着一股怪臭的酒味，令人作呕。这是因为酒精是一种利尿剂，饮酒过多会容易导致体内 缺水 ，阻止唾液正常分泌，而唾液中的物质能分解并冲走“有味细菌”，故一旦过量饮酒，必然会加重口臭。 \\n2. 辛辣 食物。如生活中常用到的 葱 、蒜等辛 辣食 物调料，这些调料伴有刺激性气味，用餐后容易留在口中，如果吃太多，这些气味可滞留口中长达24小时，不论你多么使劲刷牙。 \\n3. 薄荷 糖。很多人都喜欢嚼薄荷糖来清新口气消除口臭，殊不知，这种做法弊大于利。美国芝加哥 口腔 科专家杰西卡·埃默里博士表示，大多数薄荷糖含有蔗糖即“细菌的美食”，细菌在分解糖的过程中会释放硫化物，因而会加重口臭。 \\n3 口臭是怎么回事？ 回顶部 \\n4.重口味 食品 。如臭冬瓜、臭豆腐、臭 鸡蛋 等，这些带臭字的 食物 ，往往都会带有强烈的刺激性气味，是食物引发 口臭 的直接原因。 \\n5.咸类食物。如咸蟹、 虾 酱、蟹糊、咸 鱼 等，食用后会使人口中带有一股咸腥味。 \\n6.干果。干果不仅含有大量促进细菌滋生的糖，而且含有大量的不溶性膳食纤维，更容易导致 口腔 及牙缝间糖的聚集，以致牙釉质表面和牙龈周围堆积大量的菌斑，就会导致龋齿和牙周疾病，形成口臭。 \\n7.高 蛋 白食物。蛋白质摄入过量，超过身体的需求，身体就会将其分解为碳水化物用作能量。分解过程会产生氨，即尿味，通过口腔排出体外;而有些人群体内无法充分分解高蛋白质或一些特定蛋白，就会产生一种很像腐烂鱼肉的气味。 \\n4 4种食物 有效帮助你消除口臭 回顶部 \\n4种食物 有效帮助你消除口臭 \\n1. 香芹菜 \\n这种草本植物最有助于消除口中的异味，尤其是烟味。如果手边一时找不到香芹菜，香菜、 薄荷 也能起到去除 口腔异味 的作用。为了达到更好的效果，这些东西嚼得时间越长越好，或者用来沏茶喝。此外，上述这几种草本植物对消化也有好处。 \\n2. 酸奶 \\n最新的研究表明，每天坚持喝酸奶可以降低口腔中的硫化氢含量，因为这种物质正是口腔异味的罪魁祸首。按时喝酸奶还可以阻止口腔中有害细菌的产生，这些细菌会引起牙床疾病或 牙菌斑 。但是，只有天然的酸奶具有这样的功效，含糖的酸奶起不到这种效果。 \\n3. 富含纤维素的蔬菜和水果 \\n包括 苹果 、 胡萝卜 和芹菜等。这些蔬菜和水果有助于分泌大量唾液。唾液不仅能湿润口腔，还能清除附着在牙齿上面或塞在牙缝中的食物残渣。这些食物残渣也是导致口腔异味的原因之一。 \\n4. 含大量 维生素C 的食物 \\n浆果、柑橘、西瓜和其他含有大量 维生素 C的食物能使口腔形成一个不利于细菌生长的环境。经常摄入维生素C对牙床的健康也非常有用。但要注意，维生素C应该从天然食品，而非食品添加剂中摄入，因为添加剂可能会使消化 功能紊乱 。 （图片来源：视觉中国）'),\n",
       " ('其他',\n",
       "  '\\n1 时尚弄潮儿怎能不败Moschino欲爆街单品！ 回顶部 \\nMoschino 2016 春夏系列 刚刚发布，所有人的内心都按捺不住喜悦。他家的每件 新品 都想买买买有木有!作为 时尚 弄潮儿的你，怎能不在第一时间入手这即将爆红的Moschino新一季的时髦 单品 ！ \\n点击图片进入下一页>> \\nMoschino 2016春夏欲爆街 时装 ： \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n2 时尚弄潮儿怎能不败Moschino欲爆街单品！ 回顶部 \\nMoschino 2016春夏欲爆街包袋： \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n3 时尚弄潮儿怎能不败Moschino欲爆街单品！ 回顶部 \\nMoschino 2016春夏欲爆街 配件 ： \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>> \\n点击图片进入下一页>>'),\n",
       " ('其他',\n",
       "  '\\n1 脸上长痘痘是什么原因？ 回顶部 \\n脸上长痘痘是什么原因? \\n额头长痘痘是什么原因 \\n如果额头长痘痘了，说明这个人心火旺盛，血液循环不畅。日常生活中精神压力过大，脾气差是主要表现。 \\n针对额头长痘痘的朋友，我们建议应早睡早起，多喝水，对去除额头上痘痘具有很好的效果。 \\n鼻翼长痘痘是什么原因 \\n鼻翼长痘痘也是比较常见的现象，一般来讲，鼻翼长痘痘与生殖系统有关。鼻翼长痘痘的主要原因有：1.颈椎有毛病、2.卵巢出现问题、3.生殖系统疾病、4.消化不良、5.内分泌失调。 \\n针对鼻翼长痘痘的朋友，日常生活中不要过度纵欲或禁欲，如果是疾病引起的，一定要及时治疗。 \\n双眉间长痘痘是什么原因 \\n双眉间长痘痘即我们说的印堂痘，有印堂痘的朋友体外症状有：胸闷，心律不整，心悸。 \\n有印堂痘的朋友生活中要注意饮食，尽量不吃有刺激性的食物，如烟、酒、槟榔、酒、辛辣刺激食物，多进行有氧运动。 \\n鼻头长痘痘是什么原因 \\n日常生活中有胃火，消化不好的朋友长痘痘的部位通常在鼻头。 \\n这类朋友需要少吃冰冷食物，保护好肠胃。 \\n左脸颊长痘痘是什么原因 \\n如果一个人生活中易怒，经常发脾气，那么这个人左脸颊长痘痘的情况是比较常见的，怒伤肝，左脸颊长痘痘的朋友肝功能肯定不好。 \\n左脸颊长痘痘的朋友一定要保持情绪的平稳，保持心情愉快。 \\n2 脸上长痘痘是什么原因？ 回顶部 \\n右脸颊长痘痘是什么原因 \\n左脸与右脸长痘痘反应身体的情况都不相同，右脸颊长痘痘的朋友一般为肺功能失常。 \\n平时尽量少吃芒果、芋头、海鲜等食物，注意呼吸道系统的保养。 \\n唇周边长痘痘是什么原因 \\n日常生活中使用含氟过量的牙膏会导致唇周边长痘痘，同时便秘的患者也容易出现唇周边长痘痘。 \\n唇周边长痘痘的朋友应调整饮食习惯，多吃高纤维的蔬菜水果。 \\n太阳穴长痘痘是什么原因 \\n经常吃饼干，饮料等加工食品的朋友容易出现太阳穴长痘痘。 \\n此时需要养成良好的饮食习惯。 \\n下巴长痘痘是什么原因 \\n内分泌失调的朋友容易长痘痘在下巴部位。 \\n生活中避免吃冰棒等冰冷的食品。 （图片来源：视觉中国）')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in fashion_web_filter if t[0]=='其他'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5868it [00:45, 129.67it/s]"
     ]
    }
   ],
   "source": [
    "wx = []\n",
    "wx_count = Counter()\n",
    "with open(\"/data/xueyou/fashion/sku/weixin_content_2017_10/000001_0\") as f:\n",
    "    for line in tqdm(f):\n",
    "        content = line.strip().split(\"\\x01\")[1]\n",
    "        if len(content) > 100:\n",
    "            content = tokenize_text(content)\n",
    "            labels =best_model.predict([content],k=2)[0][0]\n",
    "            label = labels[0]\n",
    "            wx_count[label] += 1\n",
    "            wx.append((label,content))\n",
    "            if len(wx) == 5000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__其他\t4705\t94.1\n",
      "__label__美搭\t42\t0.84\n",
      "__label__美容\t58\t1.16\n",
      "__label__居家\t19\t0.38\n",
      "__label__母婴\t54\t1.08\n",
      "__label__数码\t83\t1.66\n",
      "__label__手机\t34\t0.6799999999999999\n",
      "__label__型男\t5\t0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5868it [01:00, 97.69it/s] "
     ]
    }
   ],
   "source": [
    "wxcnt = sum(wx_count.values())\n",
    "for k,v in wx_count.items():\n",
    "    print(k,v,v/wxcnt*100,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test service\n",
    "test = '''这款深蓝色色调的卫衣上衣搭配浅蓝色衬衣点缀轻松打造出假两件的感觉尽显休闲个性感，搭配身下的白色修身喇叭裤更是吸睛，搭配起来轻松起范儿。\n",
    "\n",
    "上衣穿在身上轻松显休闲魅力，宽松的版型穿在身上舒适轻松，搭配深蓝色色调更显低调内涵气质，修饰肌肤更显白皙透亮。\n",
    "\n",
    "袖口采用系带收紧的设计随着手臂的摆动更显优雅魅力，浅蓝色衬衣袖子点缀搭配更显个性有型，修饰手臂线条更显纤细修长。\n",
    "\n",
    "衣摆处同样采用浅蓝色牛仔点缀，圆弧型的设计修饰身材更显修长身姿，宽松的版型搭配身下的修身牛仔裤显瘦效果十足。\n",
    "\n",
    "身下的白色牛仔裤穿在身上更显优雅魅力感，上衣深色色调搭配下衣浅色色调更显舒适吸睛，搭配起来合适极了，膝盖以下小腿处喇叭裤裤型的点缀更显优雅魅力。\n",
    "\n",
    "九分裤裤长露出纤细的脚踝线条，搭配毛边的裤腿更显时尚个性，脚下的黑色尖头皮质鞋子更显个性吸睛，整个搭配时尚新潮极了。\n",
    "\n",
    "声明：图片由编辑江小鱼整编而来，文：编辑闪闪原创内容主编M君审核，内容未经允许请勿转载抄袭必究\n",
    "\n",
    "本文为一点号作者原创，未经授权不得转载'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': [{'intent': 1, 'name': '美搭', 'prob': 0.9986304044723511},\n",
       "  {'intent': 7, 'name': '型男', 'prob': 0.0012667056871578097},\n",
       "  {'intent': 4, 'name': '美容', 'prob': 0.00011280224862275645},\n",
       "  {'intent': 6, 'name': '母婴', 'prob': 2.7931540898862295e-05},\n",
       "  {'intent': 0, 'name': '其他', 'prob': 1.1623461432463955e-05},\n",
       "  {'intent': 2, 'name': '手机', 'prob': 1.0245653356832918e-05},\n",
       "  {'intent': 5, 'name': '居家', 'prob': 1.0086097063322086e-05},\n",
       "  {'intent': 3, 'name': '数码', 'prob': 1.0000003385357559e-05}],\n",
       " 'query': '这款深蓝色色调的卫衣上衣搭配浅蓝色衬衣点缀轻松打造出假两件的感觉尽显休闲个性感，搭配身下的白色修身喇叭裤更是吸睛，搭配起来轻松起范儿。\\n\\n上衣穿在身上轻松显休闲魅力，宽松的版型穿在身上舒适轻松，搭配深蓝色色调更显低调内涵气质，修饰肌肤更显白皙透亮。\\n\\n袖口采用系带收紧的设计随着手臂的摆动更显优雅魅力，浅蓝色衬衣袖子点缀搭配更显个性有型，修饰手臂线条更显纤细修长。\\n\\n衣摆处同样采用浅蓝色牛仔点缀，圆弧型的设计修饰身材更显修长身姿，宽松的版型搭配身下的修身牛仔裤显瘦效果十足。\\n\\n身下的白色牛仔裤穿在身上更显优雅魅力感，上衣深色色调搭配下衣浅色色调更显舒适吸睛，搭配起来合适极了，膝盖以下小腿处喇叭裤裤型的点缀更显优雅魅力。\\n\\n九分裤裤长露出纤细的脚踝线条，搭配毛边的裤腿更显时尚个性，脚下的黑色尖头皮质鞋子更显个性吸睛，整个搭配时尚新潮极了。\\n\\n声明：图片由编辑江小鱼整编而来，文：编辑闪闪原创内容主编M君审核，内容未经允许请勿转载抄袭必究\\n\\n本文为一点号作者原创，未经授权不得转载',\n",
       " 'version': '0'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\"https://alpha-surreal.aidigger.com/api/v1/classification/category/article/0\",json={\"query\":test}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [zhuyuheEnv]",
   "language": "python",
   "name": "Python [zhuyuheEnv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

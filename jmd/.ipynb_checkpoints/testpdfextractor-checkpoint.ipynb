{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pdftree\n",
    "根节点为virtualNode，根据headline及其level构建pdftree。\n",
    "没有headline的默认为根节点的子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pdfextractor import extractor\n",
    "import pdfextractor\n",
    "import pickle\n",
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#根据文章与pdf的映射，找出文章句子与pdf句子的匹配关系\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        return t2\n",
    "    return ''\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        s = MatchTwoText(text, pdftext, threshold)\n",
    "        if s != '':\n",
    "            return s\n",
    "    return ''\n",
    "\n",
    "#map和article中有24篇重合，24篇中有11篇有标注的\n",
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "dataJoin = dataJoin.rename(columns = {0:'文本', 1: '意图', 2: 'pdfurl'})\n",
    "pdfurls = dataJoin.pdfurl.unique()\n",
    "for url in pdfurls:\n",
    "    try :\n",
    "        pdflist = extractPDF(url, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    urldata = dataJoin[dataJoin.pdfurl == url]\n",
    "    for i in urldata.index:\n",
    "        s = isMatch(dataJoin.loc[i, '文本'], pdflist, 0.6)\n",
    "        print s\n",
    "        dataJoin.loc[i, 'pdf文本'] = s\n",
    "        \n",
    "dataJoin[dataJoin['pdf文本'] != ''].to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')\n",
    "d.columns = ['index','文本', '意图', 'pdfurl', 'pdf文本']\n",
    "d = d[d['文本'].apply(lambda x: x.__len__() > 10)]\n",
    "d = d[d['文本'].duplicated() == False]\n",
    "d.to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None,index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "jmd_pdf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "jmd_pdf_map = pd.DataFrame()\n",
    "jmd_pdf_map['jmdtext'] = ''\n",
    "jmd_pdf_map['pdftext'] = ''\n",
    "jmd_pdf_map['pdfurl'] = ''\n",
    "pdfurl = ''\n",
    "i = 0\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "    print(set(ct1))\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        jmd_pdf_map.loc[i, 'jmdtext'] = t1\n",
    "        jmd_pdf_map.loc[i, 'pdftext'] = t2\n",
    "        jmd_pdf_map.loc[i, 'pdfurl'] = pdfurl\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        if MatchTwoText(text, pdftext, threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_node_texts(pdf_nodes):\n",
    "    '''Given a list of nodes, get the texts of these nodes\n",
    "    '''\n",
    "    texts = []\n",
    "    for node in pdf_nodes:\n",
    "        texts.append(node.obj.get_text())\n",
    "    return texts\n",
    "\n",
    "#percent: 取pdf的前多少页\n",
    "def extractPDF(pdfPath, percent, source = ['table', 'text']):\n",
    "    savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "    ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "    nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "    textList = []\n",
    "    textNodes = []\n",
    "    tableList = []\n",
    "    tableNodes = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.page.Table):\n",
    "            if 'table' in source:\n",
    "                tableNodes.append(node)\n",
    "        elif (not isinstance(node.obj, pdfextractor.pdftree.VirtualNode)) & (not isinstance(node.obj, pdfextractor.page.Catalog)):\n",
    "            if 'text' in source:\n",
    "                textNodes.append(node)\n",
    "\n",
    "    tableList = get_node_texts(tableNodes)\n",
    "    tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "    #二维数组转化为一维\n",
    "    tableList = sum(tableList,[])\n",
    "    textList = get_node_texts(textNodes)\n",
    "    textList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "    textList = [t.replace('\\n', '') for t in textList]\n",
    "    textList = filter(lambda x: x != '', textList)\n",
    "    \n",
    "    pdf = []\n",
    "    pdf.append(textList)\n",
    "    pdf.append(tableList)\n",
    "    pdf = sum(pdf, [])\n",
    "    print pdf.__len__()\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "#     def write_unicode(text, charset='utf-8'):\n",
    "#         return text.encode(charset)\n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt', 'w')  \n",
    "#     for text in textList:  \n",
    "#         fileObject.write(text)  \n",
    "#         fileObject.write('\\n')\n",
    "#     fileObject.close()\n",
    "#     fileObject2 = open(savePath + 'cxkjTableList.txt', 'w')  \n",
    "#     for table in tableList:  \n",
    "#         fileObject2.write(write_unicode(table))  \n",
    "#         fileObject2.write('\\n')  \n",
    "#     fileObject2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']['pdf文本']\n",
    "pdftext.to_csv('/home/zhuyuhe/mydata/jmd/predict/pdftext.txt', header = None, index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#计算pdf意图符合文章意图的句子比例\n",
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']\n",
    "pdftext_intent = pd.read_csv('/home/zhuyuhe/mydata/jmd/predict/cxkjpdftext_predict.txt', header = None)\n",
    "pdftext['pdfintent'] = pdftext_intent.values\n",
    "pdftext['pdfintent'] = pdftext['pdfintent'].apply(lambda x: x.replace('__label__', ''))\n",
    "pdftext['意图'] = pdftext['意图'].apply(lambda x: '|'.join(x.split('|')[:2]))\n",
    "bol = pdftext['意图'] == pdftext['pdfintent']\n",
    "print \"文本句子有 \" + str(len(bol)) + \" 句\"\n",
    "print \"pdf意图符合文章意图的句子比例为\" + str(bol.value_counts()[1] * 1.0 / len(bol) * 100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print qtjypdftext[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "qtjypdftext = extractPDF('http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF',0.8, ['text'])\n",
    "qtjypdftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "fp = open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb')\n",
    "jmdata_mapping = pickle.load(fp)\n",
    "\n",
    "content_url_map = {}\n",
    "for d in jmdata_mapping[2:]:\n",
    "    content_url_map[d['pdf_url']] = d['content']\n",
    "\n",
    "urls = content_url_map.keys()\n",
    "\n",
    "num = 1\n",
    "result = {}\n",
    "\n",
    "for path in urls:\n",
    "    print \"Article \" + str(num) + \": \" \n",
    "    num += 1\n",
    "    \n",
    "    print path\n",
    "    pdfurl = path\n",
    "    \n",
    "    cxkj = content_url_map[path]\n",
    "    print cxkj\n",
    "    cxkj = cxkj.strip().encode('utf-8').split('。')\n",
    "    cxkj = [x.replace('\\n','') for x in cxkj]\n",
    "    try :\n",
    "        pdflist = extractPDF(path, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    \n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt')\n",
    "#     textlist = fileObject.read().split('\\n')\n",
    "#     fileObject = open(savePath + 'cxkjTableList.txt')\n",
    "#     tablelist = fileObject.read().split('\\n')\n",
    "#     fileObject.close()\n",
    "\n",
    "#     PDFTextList = []\n",
    "#     PDFTextList.append(textlist)\n",
    "#     PDFTextList.append(tablelist)\n",
    "#     PDFTextList = sum(PDFTextList, [])\n",
    "#     print PDFTextList.__len__()\n",
    "    print('**************************')\n",
    "    count = 0\n",
    "    for text in pdflist:\n",
    "        if not (len(text) == 0):\n",
    "            if isMatch(text, pdflist, 0.6):\n",
    "                count+=1\n",
    "    print str(count * 1.0/ cxkj.__len__() * 100) + '% 的句子来自PDF'\n",
    "    result[path] = count * 1.0/ cxkj.__len__() * 100\n",
    "    print('***************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = np.array(result.values())\n",
    "result[result != 0]\n",
    "#0%的原因： 1.科大讯飞  -  表格描述；上一季度财报描述  ×2 \n",
    "#           2.新南洋    -  财报中大部分均为表格，并且文章使用了其他季度的财报\n",
    "#           3.中国高科  -  前两句话描述财报表格，\n",
    "#           4.洪涛股份  -  文章与财报不匹配，2015年年报 = 2016年第一季度财报？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#percent: 取pdf的前多少页\n",
    "def extractPDF(pdfPath, percent, source = ['table', 'text']):\n",
    "    savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "    ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "    nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "    textList = []\n",
    "    textNodes = []\n",
    "    tableList = []\n",
    "    tableNodes = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.page.Table):\n",
    "            if 'table' in source:\n",
    "                tableNodes.append(node)\n",
    "        elif (not isinstance(node.obj, pdfextractor.pdftree.VirtualNode)) & (not isinstance(node.obj, pdfextractor.page.Catalog)):\n",
    "            if 'text' in source:\n",
    "                textNodes.append(node)\n",
    "\n",
    "    tableList = get_node_texts(tableNodes)\n",
    "    tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "    #二维数组转化为一维\n",
    "    tableList = sum(tableList,[])\n",
    "    textList = get_node_texts(textNodes)\n",
    "    textList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "    textList = [t.replace('\\n', '') for t in textList]\n",
    "    textList = filter(lambda x: x != '', textList)\n",
    "    \n",
    "    pdf = []\n",
    "    pdf.append(textList)\n",
    "    pdf.append(tableList)\n",
    "    pdf = sum(pdf, [])\n",
    "    print pdf.__len__()\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "#     def write_unicode(text, charset='utf-8'):\n",
    "#         return text.encode(charset)\n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt', 'w')  \n",
    "#     for text in textList:  \n",
    "#         fileObject.write(text)  \n",
    "#         fileObject.write('\\n')\n",
    "#     fileObject.close()\n",
    "#     fileObject2 = open(savePath + 'cxkjTableList.txt', 'w')  \n",
    "#     for table in tableList:  \n",
    "#         fileObject2.write(write_unicode(table))  \n",
    "#         fileObject2.write('\\n')  \n",
    "#     fileObject2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    if isinstance(n.obj, pdfextractor.pdftree.VirtualNode):\n",
    "        continue\n",
    "    if len(n.obj.get_text()) <= 25:\n",
    "        continue\n",
    "    else:\n",
    "        text = n.obj.get_text()\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        text_nodes.append(n)\n",
    "        print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "node= text_nodes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isinstance(node.obj,pdfextractor.paragraph.Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_child_headlines(pdf_node):\n",
    "    '''Get headlines of children of a node\n",
    "    '''\n",
    "    headlines = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline):\n",
    "            headlines.append(node)\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_child_paragraphs(pdf_node):\n",
    "    '''Get paragraphs of children of a node\n",
    "    '''\n",
    "    paragraphs = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "            paragraphs.append(node)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_paragraph_headlines(pdf_node):\n",
    "    '''Get headlines of a paragraph\n",
    "    Input:\n",
    "        - pdf_node: a pdf node\n",
    "    Output:\n",
    "        - headlines: a list of sorted headline nodes\n",
    "        - texts: a list of sorted headline texts\n",
    "    '''\n",
    "    headlines = []\n",
    "    node = pdf_node.parent\n",
    "    while not isinstance(node.obj,pdfextractor.pdftree.VirtualNode):\n",
    "        headlines.append(node)\n",
    "        node = node.parent\n",
    "    headlines = list(reversed(headlines))\n",
    "    return headlines, get_node_texts(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print get_paragraph_headlines(text_nodes[15])[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "host = 'https://alpha-surreal.aidigger.com/api/v1/classification/intent/finance/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hd_intents = []\n",
    "all_intents = []\n",
    "for node in text_nodes:\n",
    "    content = node.obj.get_text()\n",
    "    headline = get_paragraph_headlines(node)[1][-1]\n",
    "    intents = requests.post(host,json={\"query\":content}).json()\n",
    "    head_intents = requests.post(host,json={\"query\":headline}).json()\n",
    "    for i,item in enumerate(head_intents['predict']):\n",
    "        intents['predict'][i]['prob'] += item['prob']\n",
    "    all_intents.append(intents)\n",
    "    intent = max(intents['predict'],key=lambda item:item['prob'])\n",
    "    hd_intents.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_intent(it):\n",
    "    for i,item in enumerate(it):\n",
    "        print i,item['name'],item['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_intent(all_intents[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,intent in enumerate(hd_intents):\n",
    "    print i\n",
    "    print text_nodes[i]\n",
    "    print ' ==> '.join(get_paragraph_headlines(text_nodes[i])[1])\n",
    "    print intent['name'],'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Anaconda python2",
   "language": "python",
   "name": "anpython2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

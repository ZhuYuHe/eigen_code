{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pdftree\n",
    "根节点为virtualNode，根据headline及其level构建pdftree。\n",
    "没有headline的默认为根节点的子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pdfextractor import extractor\n",
    "import pdfextractor\n",
    "import pickle\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#根据文章与pdf的映射，找出文章句子与pdf句子的匹配关系\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        return t2\n",
    "    return ''\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        s = MatchTwoText(text, pdftext, threshold)\n",
    "        if s != '':\n",
    "            return s\n",
    "    return ''\n",
    "\n",
    "#map和article中有24篇重合，24篇中有11篇有标注的\n",
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "dataJoin = dataJoin.rename(columns = {0:'文本', 1: '意图', 2: 'pdfurl'})\n",
    "pdfurls = dataJoin.pdfurl.unique()\n",
    "for url in pdfurls:\n",
    "    try :\n",
    "        pdflist = extractPDF(url, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    urldata = dataJoin[dataJoin.pdfurl == url]\n",
    "    for i in urldata.index:\n",
    "        s = isMatch(dataJoin.loc[i, '文本'], pdflist, 0.6)\n",
    "        print s\n",
    "        dataJoin.loc[i, 'pdf文本'] = s\n",
    "        \n",
    "dataJoin[dataJoin['pdf文本'] != ''].to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')\n",
    "d.columns = ['index','文本', '意图', 'pdfurl', 'pdf文本']\n",
    "d = d[d['文本'].apply(lambda x: x.__len__() > 10)]\n",
    "d = d[d['文本'].duplicated() == False]\n",
    "d.to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None,index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = \"创显将大力发展软硬件结合的教学解决方案，配套以不同层次的专业培训服务\"\n",
    "pdflist = ['2017年，公司将大力发展软硬件结合的视频教学解决方案，形成精品录播室，标准录播，配套以不同的专业培训服务', '2017年，公司将在既有的教师化信息能力平台业务基础上，进一步深化细化培养服务']\n",
    "print(isMatch(a, pdflist, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdfurl = ''\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "# fileObject = open(savePath + 'jmd_pdf_map.txt', 'w') \n",
    "def write_unicode(text, charset='utf-8'):\n",
    "    return text.encode(charset)\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "#     print t1\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "#     print commonL\n",
    "#     print ct1\n",
    "#     print set(ct1).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "#         fileObject.write(t1.encode('utf-8'))\n",
    "#         fileObject.write('\\t')\n",
    "#         fileObject.write(t2.encode('utf-8'))\n",
    "#         fileObject.write('\\t')\n",
    "#         fileObject.write(pdfurl)\n",
    "#         fileObject.write('\\n')\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        if MatchTwoText(text, pdftext, threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_node_texts(pdf_nodes):\n",
    "    '''Given a list of nodes, get the texts of these nodes\n",
    "    '''\n",
    "    texts = []\n",
    "    for node in pdf_nodes:\n",
    "        text = node.obj.get_text()\n",
    "        if len(text) <= 25:\n",
    "            continue\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "#percent: 取pdf的前多少页\n",
    "def extractPDF(pdfPath, percent, source = ['table', 'text', 'para'], headline = None):\n",
    "    savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "    ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "    nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "    paraList = []\n",
    "    textList = []\n",
    "    textNodes = []\n",
    "    tableList = []\n",
    "    tableNodes = []\n",
    "    senList = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.pdftree.VirtualNode):\n",
    "            continue\n",
    "        if isinstance(node.obj, pdfextractor.page.Table):\n",
    "            tableNodes.append(node)\n",
    "        elif  not isinstance(node.obj, pdfextractor.page.Catalog):\n",
    "            textNodes.append(node)\n",
    "    if 'table' in source:\n",
    "        tableList = get_node_texts(tableNodes)\n",
    "        tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "        #二维数组转化为一维\n",
    "        tableList = sum(tableList,[])\n",
    "    textList = get_node_texts(textNodes)\n",
    "    if 'para' in source:\n",
    "        paraList = [t.replace('\\n', '') for t in textList]\n",
    "        paraList = filter(lambda x: x != '', paraList)\n",
    "    elif 'text' in source:\n",
    "        senList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "        senList = [t.replace('\\n', '') for t in senList]\n",
    "        senList = filter(lambda x: x != '', senList)\n",
    "\n",
    "    pdf = []\n",
    "#     pdf.append(textList)\n",
    "#     pdf.append(tableList)\n",
    "#     pdf = sum(pdf, [])\n",
    "    pdf.extend(senList)\n",
    "    pdf.extend(tableList)\n",
    "    pdf.extend(paraList)\n",
    "    print pdf.__len__()\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "#     \n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt', 'w')  \n",
    "#     for text in textList:  \n",
    "#         fileObject.write(text)  \n",
    "#         fileObject.write('\\n')\n",
    "#     fileObject.close()\n",
    "#     fileObject2 = open(savePath + 'cxkjTableList.txt', 'w')  \n",
    "#     for table in tableList:  \n",
    "#         fileObject2.write(write_unicode(table))  \n",
    "#         fileObject2.write('\\n')  \n",
    "#     fileObject2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print MatchTwoText('报告显示，方直科技在一季度实现营业收入34,743,435.23元，由于教育系统征订销售收入和其他产品销售收入的增加，营收同比增长5.48%。',\n",
    "                   '公司在2016年第一季度实现营业收入34,743,435.23元 ，营业收入较上年同期增长5.48%，主要来自于教育系统征订销售收入增加和其他产品销售收入增加。公司核心产品业务及其结构未发生重大变化，金太阳教育软件的开发、销售业务仍是公司的核心业务。华南、华北和华东三个地区是公司产品销售比较集中的区域，报告期内各地区销售收入占主营业务收入比例分别为 70.48%、16.55%、7.2%。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://disclosure.szse.cn/finalpage/2016-10-25/1202780794.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct Pdf Tree time: 0s\n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.374 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.2857142857% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 7s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "63.6363636364% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "28.5714285714% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-26/1203386046.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 5s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203340942.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 20s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 50s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "66.6666666667% 的句子来自PDF\n",
      "***************************\n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-15/601801_2016_n.pdf\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 42s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "58.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-07-28/1203739610.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 60s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "50.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-06-20/1203635303.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 40s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "61.5384615385% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-08-10/1203778984.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 51s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "53.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-28/1203210341.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 60s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "78.9473684211% 的句子来自PDF\n",
      "***************************\n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2016-08-25/600661_2016_z.pdf\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 22s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.4705882353% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-07-28/1203751786.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 16s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "31.8181818182% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-25/1203379575.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.9230769231% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-05-10/1203508904.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 37s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "81.4814814815% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-24/1203360123.PDF\n",
      "Download pdf time: 32s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 49s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "47.0588235294% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-18/1203174359.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "60.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203341493.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 44s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "54.5454545455% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 22s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "69.2307692308% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-07-26/1203737887.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 18s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-21/1203181705.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 69s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.1904761905% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-11/1203274908.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.9230769231% 的句子来自PDF\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "seasonArticle = ['http://disclosure.szse.cn/finalpage/2016-10-25/1202780794.PDF', 'http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF', 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF','http://disclosure.szse.cn/finalpage/2017-04-26/1203386046.PDF']\n",
    "yearlyArticle = [u'http://www.cninfo.com.cn/finalpage/2017-04-19/1203340942.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF',\n",
    "                 u'http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-15/601801_2016_n.pdf', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-07-28/1203739610.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-06-20/1203635303.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-08-10/1203778984.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-28/1203210341.PDF', \n",
    "                 u'http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2016-08-25/600661_2016_z.pdf', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-07-28/1203751786.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-25/1203379575.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-05-10/1203508904.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-24/1203360123.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-18/1203174359.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-19/1203341493.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-07-26/1203737887.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-21/1203181705.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-11/1203274908.PDF']\n",
    "\n",
    "def splitByPeriod(P):\n",
    "    \"\"\"\n",
    "    split paragraph to sentences\n",
    "    \"\"\"\n",
    "    senList = sum([t.encode('utf-8').split('。') for t in P],[])\n",
    "    senList = [t.replace('\\n', '') for t in senList]\n",
    "    senList = filter(lambda x: x != '', senList)\n",
    "    return senList\n",
    "\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "fp = open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb')\n",
    "jmdata_mapping = pickle.load(fp)\n",
    "\n",
    "content_url_map = {}\n",
    "for d in jmdata_mapping[2:]:\n",
    "    content_url_map[d['pdf_url']] = d['content']\n",
    "\n",
    "urls = content_url_map.keys()\n",
    "\n",
    "num = 1\n",
    "result = {}\n",
    "jmdata_map_headline = {}\n",
    "\n",
    "def parsePDF(urls,style, cond):  \n",
    "    jmdata_map_headline[style] = {}\n",
    "    for pdfurl in urls:\n",
    "        print pdfurl\n",
    "        jmdata_map_headline[style][pdfurl] = {}\n",
    "\n",
    "        cxkj = content_url_map[pdfurl]\n",
    "        #print cxkj\n",
    "        cxkj = cxkj.strip().encode('utf-8').split('。')\n",
    "        cxkj = [x.replace('\\n','') for x in cxkj]\n",
    "\n",
    "        try :\n",
    "            pdflist = getPara(pdfurl, 0.5, cond)\n",
    "        except BaseException:\n",
    "            print 'error extractPDF'\n",
    "            continue\n",
    "\n",
    "        print \"------\"\n",
    "        jmdata_map_headline[style][pdfurl]['content'] = cxkj\n",
    "        jmdata_map_headline[style][pdfurl]['para'] = pdflist\n",
    "        jmdata_map_headline[style][pdfurl]['sen'] = splitByPeriod(pdflist)\n",
    "        jmdata_map_headline[style][pdfurl]['mapcontent'] = []\n",
    "#         for i in cxkj:\n",
    "#             print i\n",
    "#             print '-'\n",
    "#         print '**********'\n",
    "#         for i in pdflist:\n",
    "#             print i\n",
    "#             print '-'\n",
    "\n",
    "    #     fileObject = open(savePath + 'cxkjTextList.txt')\n",
    "    #     textlist = fileObject.read().split('\\n')\n",
    "    #     fileObject = open(savePath + 'cxkjTableList.txt')\n",
    "    #     tablelist = fileObject.read().split('\\n')\n",
    "    #     fileObject.close()\n",
    "\n",
    "    #     PDFTextList = []\n",
    "    #     PDFTextList.append(textlist)\n",
    "    #     PDFTextList.append(tablelist)\n",
    "    #     PDFTextList = sum(PDFTextList, [])\n",
    "    #     print PDFTextList.__len__()\n",
    "        count = 0\n",
    "        for text in cxkj:\n",
    "            if not (len(text) == 0):\n",
    "                if isMatch(text, pdflist, 0.6):\n",
    "                    jmdata_map_headline[style][pdfurl]['mapcontent'].append(text)\n",
    "                    count+=1\n",
    "\n",
    "        print str(count * 1.0/ cxkj.__len__() * 100) + '% 的句子来自PDF'\n",
    "        result[pdfurl] = count * 1.0/ cxkj.__len__() * 100\n",
    "        print('***************************')\n",
    "    \n",
    "# fileObject.close()\n",
    "\n",
    "parsePDF(seasonArticle, 'season', ['重大风险提示', '业务回顾和展望'])\n",
    "parsePDF(yearlyArticle, 'year', ['讨论与分析', '公司业务概要'])\n",
    "\n",
    "#parsePDF(['http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF'], 'season', ['重大风险提示', '业务回顾和展望'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPara(pdfurl, percent = 0.5, cond = ['业务回顾和展望', '重大风险提示']):\n",
    "    ex = extractor.StockFinanceExtractor(pdfurl, percent)\n",
    "    nodes = ex.get_pdf_objects()\n",
    "    headlines = getHeadlines(nodes, 5)\n",
    "#     print 'headlines length : ' + str(len(headlines))\n",
    "    targethl = []\n",
    "    res = []\n",
    "    for hl in headlines:\n",
    "        for c in cond:\n",
    "            if c in hl.obj.get_text():\n",
    "                targethl.append(hl)\n",
    "#     print 'targethl :' + str(len(targethl))\n",
    "#     for t in targethl:\n",
    "#         print t.obj.get_text()\n",
    "    for t in targethl:\n",
    "        res.extend(get_para_recu(t))\n",
    "    return res\n",
    "    \n",
    "def get_para_recu(node):\n",
    "    res = []\n",
    "    if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "        return res\n",
    "    child_headlines = get_child_headlines(node)\n",
    "    child_paras = get_child_paragraphs(node)\n",
    "    for c in child_paras:\n",
    "        res.append(filter_text(c.obj.get_text()))\n",
    "    for c in child_headlines:\n",
    "        res.extend(get_para_recu(c))\n",
    "    return res\n",
    "\n",
    "def filter_text(text):\n",
    "    if len(text) <= 25:\n",
    "        return ''\n",
    "    if u'□' in text or u'√' in text:\n",
    "        return ''\n",
    "    return text\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def get_child_headlines(pdf_node):\n",
    "    '''Get headlines of children of a node\n",
    "    '''\n",
    "    headlines = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline):\n",
    "            headlines.append(node)\n",
    "    return headlines\n",
    "\n",
    "def get_child_paragraphs(pdf_node):\n",
    "    '''Get paragraphs of children of a node\n",
    "    '''\n",
    "    paragraphs = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "            paragraphs.append(node)\n",
    "    return paragraphs\n",
    "\n",
    "def getHeadlines(nodes, level):\n",
    "    \"\"\"\n",
    "    return headline-nodes from given nodes\n",
    "    \"\"\"\n",
    "    re = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline) and node.obj.level <= level:\n",
    "            re.append(node)\n",
    "    return re\n",
    "\n",
    "def getMaxLevel():\n",
    "    pass\n",
    "        \n",
    "        \n",
    "             \n",
    "\n",
    "# target = getTargetNode()\n",
    "\n",
    "# print get_child_paragraphs(get_child_headlines(get_child_headlines(target)[0])[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "12\n",
      "145\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['content'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['mapcontent'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['para'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['sen'])\n",
    "jmdata_map = dict(filter(lambda x: len(x[1]) != 0, jmdata_map.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_map_headline.pkl', 'wb') as pickle_file:\n",
    "     pickle.dump(jmdata_map_headline, pickle_file , protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_map.pkl', 'wb') as pickle_file:\n",
    "     pickle.dump(jmdata_map, pickle_file , protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']['pdf文本']\n",
    "pdftext.to_csv('/home/zhuyuhe/mydata/jmd/predict/pdftext.txt', header = None, index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#计算pdf意图符合文章意图的句子比例\n",
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']\n",
    "pdftext_intent = pd.read_csv('/home/zhuyuhe/mydata/jmd/predict/cxkjpdftext_predict.txt', header = None)\n",
    "pdftext['pdfintent'] = pdftext_intent.values\n",
    "pdftext['pdfintent'] = pdftext['pdfintent'].apply(lambda x: x.replace('__label__', ''))\n",
    "pdftext['意图'] = pdftext['意图'].apply(lambda x: '|'.join(x.split('|')[:2]))\n",
    "bol = pdftext['意图'] == pdftext['pdfintent']\n",
    "print \"文本句子有 \" + str(len(bol)) + \" 句\"\n",
    "print \"pdf意图符合文章意图的句子比例为\" + str(bol.value_counts()[1] * 1.0 / len(bol) * 100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print qtjypdftext[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = np.array(result.values())\n",
    "result[result != 0]\n",
    "#0%的原因： 1.科大讯飞  -  表格描述；上一季度财报描述  ×2 \n",
    "#           2.新南洋    -  财报中大部分均为表格，并且文章使用了其他季度的财报\n",
    "#           3.中国高科  -  前两句话描述财报表格，\n",
    "#           4.洪涛股份  -  文章与财报不匹配，2015年年报 = 2016年第一季度财报？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    if isinstance(n.obj, pdfextractor.pdftree.VirtualNode):\n",
    "        continue\n",
    "    if len(n.obj.get_text()) <= 25:\n",
    "        continue\n",
    "    else:\n",
    "        text = n.obj.get_text()\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        text_nodes.append(n)\n",
    "        print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "node= text_nodes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isinstance(node.obj,pdfextractor.paragraph.Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download pdf time: 4s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n"
     ]
    }
   ],
   "source": [
    "#抽出特定条件下（headline）的段落\n",
    "ex = extractor.StockFinanceExtractor('http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF', 0.5)\n",
    "\n",
    "nodes = ex.get_pdf_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_paragraph_headlines(pdf_node):\n",
    "    '''Get headlines of a paragraph\n",
    "    Input:\n",
    "        - pdf_node: a pdf node\n",
    "    Output:\n",
    "        - headlines: a list of sorted headline nodes\n",
    "        - texts: a list of sorted headline texts\n",
    "    '''\n",
    "    headlines = []\n",
    "    node = pdf_node.parent\n",
    "    while not isinstance(node.obj,pdfextractor.pdftree.VirtualNode):\n",
    "        headlines.append(node)\n",
    "        node = node.parent\n",
    "    headlines = list(reversed(headlines))\n",
    "    return headlines, get_node_texts(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print get_paragraph_headlines(text_nodes[15])[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "host = 'https://alpha-surreal.aidigger.com/api/v1/classification/intent/finance/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hd_intents = []\n",
    "all_intents = []\n",
    "for node in text_nodes:\n",
    "    content = node.obj.get_text()\n",
    "    headline = get_paragraph_headlines(node)[1][-1]\n",
    "    intents = requests.post(host,json={\"query\":content}).json()\n",
    "    head_intents = requests.post(host,json={\"query\":headline}).json()\n",
    "    for i,item in enumerate(head_intents['predict']):\n",
    "        intents['predict'][i]['prob'] += item['prob']\n",
    "    all_intents.append(intents)\n",
    "    intent = max(intents['predict'],key=lambda item:item['prob'])\n",
    "    hd_intents.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_intent(it):\n",
    "    for i,item in enumerate(it):\n",
    "        print i,item['name'],item['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_intent(all_intents[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,intent in enumerate(hd_intents):\n",
    "    print i\n",
    "    print text_nodes[i]\n",
    "    print ' ==> '.join(get_paragraph_headlines(text_nodes[i])[1])\n",
    "    print intent['name'],'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 根据芥末堆提供的意图模板，得到意图推荐的准确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = requests.post(\"https://surreal.aidigger.com/api/v1/classification/intent/finance/0\",json={ \n",
    "    \"query\": \"公司立足校园、面向家庭提供教育信息服务，深耕教育十余年已形成覆盖校内外多场景、涵盖教育主管部门、学校、教师、家长及学生等 B 端、C 端主体的业务服务体系。公司针对不同用户群体多场景、多元化需求，持续优化服务供给，逐步构建了家校互动升级业务、EdSaaS 业务、学科升学业务及继续教育业务，报告期内公司主营业务未发生变化。\"\n",
    "}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hasCN(s):\n",
    "    \"\"\"\n",
    "    判断一段文本是否有中文\n",
    "    \"\"\"\n",
    "    for ch in s.decode('utf-8'):\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "\n",
    "dataJoin.columns = ['文本', '意图', 'pdfurl']\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: len(x) > 30)]\n",
    "dataJoin = dataJoin[dataJoin['文本'].duplicated() == False]\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: hasCN(x))]\n",
    "\n",
    "dataJoin.index = range(len(dataJoin))\n",
    "dataJoin['意图'] = dataJoin['意图'].apply(lambda x: intentMap(x))\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['意图'].apply(lambda x: x!= 'Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in dataJoin['意图'].unique():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202791188.PDF']\n",
    "b = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-25/1202780960.PDF'] \n",
    "c = dataJoin[dataJoin.pdfurl == 'http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF']\n",
    "print a.loc[119, '文本']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(dataJoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print a['意图'].value_counts()\n",
    "print b['意图'].value_counts()\n",
    "print c['意图'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "d = {'a':1, 'b':2, 'c':3}\n",
    "sorted(d.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()[d.values().index(max(d.values()))]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [zhuEnv2]",
   "language": "python",
   "name": "Python [zhuEnv2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

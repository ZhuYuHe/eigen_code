{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdfextractor import extractor\n",
    "import pdfextractor\n",
    "import pickle\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class jmdPDFMap(object):\n",
    "    \"\"\"\n",
    "    根据pdf生成文章，并计算推荐的准确率和召回率\n",
    "    意图：导语，业绩变动原因，主营业务$业务进展，未来计划\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.labels = ['导语', '业绩变动原因', '主营业务$业务进展', '未来计划', 'other']\n",
    "        self.prop = [0.2, 0.2, 0.4, 0.3, 0]\n",
    "        self.K = 0\n",
    "        #每个意图对应的句子或段落数量\n",
    "        self.num = {}\n",
    "        \n",
    "        \n",
    "    def computePR(self, article, pdfurl, mode = 'para'):\n",
    "        intentList = []\n",
    "        article_sen = self.get_article_sentence(article)\n",
    "        article_len = len(article_sen)\n",
    "        if article_len == 0:\n",
    "            return -1, -1\n",
    "        print 'article length: ' + str(article_len)\n",
    "        if mode == 'para':\n",
    "            pdftext = self.extractPDF(pdfurl, 0.8, ['para'])\n",
    "        else:\n",
    "            pdftext = self.extractPDF(pdfurl, 0.8, ['text'])\n",
    "        for t in pdftext:\n",
    "            intentList.append(self.getIntent(t))\n",
    "        if mode == 'para':\n",
    "            self.K = int(len(article_sen) * 0.5)\n",
    "        else:\n",
    "            self.K = int(len(article_sen) * 1.5)\n",
    "        for l in range(len(self.labels)):\n",
    "            self.num[self.labels[l]] = int(self.K * self.prop[l])\n",
    "        recommendList = self.getTopKintent(intentList)\n",
    "        rec_len = len(recommendList)\n",
    "        if rec_len == 0:\n",
    "            return -1, -1\n",
    "        print 'recomment list length: ' + str(rec_len)\n",
    "        P_dic = {}\n",
    "        Pcount = 0\n",
    "        Rcount = 0\n",
    "        for r in recommendList:\n",
    "            P_dic[r] = False\n",
    "        for sen in article_sen:\n",
    "            for rec in recommendList:\n",
    "                if self.MatchTwoText(sen, rec):\n",
    "                    Rcount += 1\n",
    "                    if P_dic[rec] is False:\n",
    "                        P_dic[rec] = True\n",
    "                        Pcount += 1\n",
    "        P = Pcount * 1.0 / rec_len\n",
    "        R = Rcount * 1.0 / article_len\n",
    "        print 'Pcount: ' + str(Pcount)\n",
    "        print 'Rcount: ' + str(Rcount)\n",
    "        return P, R\n",
    "        \n",
    "    def getTopKintent(self, intentlist):\n",
    "        intent = {}\n",
    "        for l in self.labels:\n",
    "            intent[l] = {}\n",
    "        \n",
    "        for i in intentlist:\n",
    "            key = i['intent']\n",
    "            intent[key][i['content']] = i['prob']\n",
    "        result = []\n",
    "        for l in self.labels:\n",
    "            intent_l = intent[l]\n",
    "            intent[l] = sorted(intent_l.items(), key=operator.itemgetter(1))\n",
    "        print \"各个段落（句子）的预测意图分布为：\"\n",
    "        for i in intent:\n",
    "            print i + \"  \" + str(len(intent[i]))\n",
    "        for l in intent.keys():\n",
    "            result.extend([d[0] for d in intent[l][:self.num[l]]])\n",
    "        return result\n",
    "        \n",
    "    def get_article_sentence(self, ar):\n",
    "        \"\"\"\n",
    "        given an article, return the list of sentences\n",
    "        \"\"\"\n",
    "        textList = ar.encode('utf-8').split('。') \n",
    "        textList = [t.replace('\\n', '') for t in textList]\n",
    "        textList = filter(lambda x: x != '', textList)\n",
    "        return textList\n",
    "\n",
    "    #percent: 取pdf的前多少页\n",
    "    def extractPDF(self, pdfPath, percent, source = ['table', 'text', 'para']):\n",
    "        savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "        ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "        nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "        paraList = []\n",
    "        textList = []\n",
    "        textNodes = []\n",
    "        tableList = []\n",
    "        tableNodes = []\n",
    "        for node in nodes:\n",
    "            if isinstance(node.obj, pdfextractor.pdftree.VirtualNode):\n",
    "                continue\n",
    "            if isinstance(node.obj, pdfextractor.page.Table):\n",
    "                tableNodes.append(node)\n",
    "            elif  not isinstance(node.obj, pdfextractor.page.Catalog):\n",
    "                textNodes.append(node)\n",
    "        if 'table' in source:\n",
    "            tableList = self.get_node_texts(tableNodes)\n",
    "            tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "            #二维数组转化为一维\n",
    "            tableList = sum(tableList,[])\n",
    "        textList = self.get_node_texts(textNodes)\n",
    "        if 'para' in source:\n",
    "            paraList = [t.replace('\\n', '') for t in textList]\n",
    "            paraList = filter(lambda x: x != '', paraList)\n",
    "        elif 'text' in source:\n",
    "            textList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "            textList = [t.replace('\\n', '') for t in textList]\n",
    "            textList = filter(lambda x: x != '', textList)\n",
    "\n",
    "        pdf = []\n",
    "    #     pdf.append(textList)\n",
    "    #     pdf.append(tableList)\n",
    "    #     pdf = sum(pdf, [])\n",
    "        pdf.extend(textList)\n",
    "        pdf.extend(tableList)\n",
    "        pdf.extend(paraList)\n",
    "        print pdf.__len__()\n",
    "\n",
    "        return pdf\n",
    "    \n",
    "    def get_node_texts(self, pdf_nodes):\n",
    "        '''\n",
    "        Given a list of nodes, get the texts of these nodes\n",
    "        '''\n",
    "        texts = []\n",
    "        for node in pdf_nodes:\n",
    "            text = node.obj.get_text()\n",
    "            if len(text) <= 25:\n",
    "                continue\n",
    "            if u'□' in text or u'√' in text:\n",
    "                continue\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def getIntent(self, text):\n",
    "        \"\"\"\n",
    "        return intent of the given text\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        query = requests.post(\"https://surreal.aidigger.com/api/v1/classification/intent/finance/0\",json={ \"query\": text}).json()\n",
    "        predict = query['predict']\n",
    "        prob = [x['prob'] for x in predict]\n",
    "        i = max(prob)\n",
    "        intent = predict[prob.index(i)]['name']\n",
    "        #print intent\n",
    "        result['content'] = text\n",
    "        result['intent'] = self.intentMap(intent)\n",
    "        result['prob'] = i\n",
    "        return result\n",
    "    \n",
    "    def intentMap(self, i):\n",
    "        \"\"\"\n",
    "        将现有意图映射到芥末堆所给的意图上去\n",
    "        \"\"\"\n",
    "        i = i.encode('utf-8')\n",
    "        if i == '意图_企业业绩__现状偏好' or i == '意图_企业业绩__现状偏坏' or i == '导语' or i == '意图_企业基本信息介绍_企业基本信息介绍':\n",
    "            return self.labels[0]\n",
    "        elif '原因' in i:\n",
    "            return self.labels[1]\n",
    "        elif '业务' in i and not '前景' in i:\n",
    "            return self.labels[2]\n",
    "        elif '前景' in i or '评论' in i:\n",
    "            return self.labels[3]\n",
    "        else:\n",
    "            return self.labels[4]\n",
    "        \n",
    "    def MatchTwoText(self, t1, t2, threshold = 0.5):\n",
    "        \"\"\"\n",
    "        检查两个句子是否匹配\n",
    "        \"\"\"\n",
    "        ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "        ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "        commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "        if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************\n",
      "article 0 :\n",
      "--------------------\n",
      "article length: 12\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 8s\n",
      "Construct Pdf Tree time: 0s\n",
      "44\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  4\n",
      "导语  0\n",
      "other  11\n",
      "业绩变动原因  4\n",
      "未来计划  3\n",
      "recomment list length: 4\n",
      "Pcount: 2\n",
      "Rcount: 8\n",
      "--PARA--  Pecision: 0.5    Recall: 0.666666666667\n",
      "--------------------\n",
      "article length: 12\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 9s\n",
      "Construct Pdf Tree time: 0s\n",
      "58\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  13\n",
      "导语  1\n",
      "other  18\n",
      "业绩变动原因  19\n",
      "未来计划  6\n",
      "recomment list length: 16\n",
      "Pcount: 3\n",
      "Rcount: 3\n",
      "--SEN--  Pecision: 0.1875    Recall: 0.25\n",
      "---------------------\n",
      "*******************************************************\n",
      "******************************************************\n",
      "article 1 :\n",
      "--------------------\n",
      "article length: 13\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 9s\n",
      "Construct Pdf Tree time: 0s\n",
      "14\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  0\n",
      "导语  0\n",
      "other  6\n",
      "业绩变动原因  0\n",
      "未来计划  1\n",
      "recomment list length: 1\n",
      "Pcount: 0\n",
      "Rcount: 0\n",
      "--PARA--  Pecision: 0.0    Recall: 0.0\n",
      "--------------------\n",
      "article length: 13\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 7s\n",
      "Construct Pdf Tree time: 0s\n",
      "13\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  0\n",
      "导语  0\n",
      "other  9\n",
      "业绩变动原因  0\n",
      "未来计划  3\n",
      "recomment list length: 3\n",
      "Pcount: 0\n",
      "Rcount: 0\n",
      "--SEN--  Pecision: 0.0    Recall: 0.0\n",
      "---------------------\n",
      "*******************************************************\n",
      "******************************************************\n",
      "article 2 :\n",
      "--------------------\n",
      "article length: 12\n",
      "Download pdf time: 5s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 4s\n",
      "Construct Pdf Tree time: 0s\n",
      "28\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  0\n",
      "导语  0\n",
      "other  17\n",
      "业绩变动原因  0\n",
      "未来计划  0\n",
      "--PARA--  Pecision: -1    Recall: -1\n",
      "--------------------\n",
      "article length: 12\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 5s\n",
      "Construct Pdf Tree time: 0s\n",
      "16\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  0\n",
      "导语  0\n",
      "other  14\n",
      "业绩变动原因  0\n",
      "未来计划  0\n",
      "--SEN--  Pecision: -1    Recall: -1\n",
      "---------------------\n",
      "*******************************************************\n",
      "******************************************************\n",
      "article 3 :\n",
      "--------------------\n",
      "article length: 19\n",
      "Download pdf time: 13s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 66s\n",
      "Construct Pdf Tree time: 0s\n",
      "974\n",
      "各个段落（句子）的预测意图分布为：\n",
      "主营业务$业务进展  62\n",
      "导语  1\n",
      "other  391\n",
      "业绩变动原因  4\n",
      "未来计划  26\n",
      "recomment list length: 7\n",
      "Pcount: 0\n",
      "Rcount: 0\n",
      "--PARA--  Pecision: 0.0    Recall: 0.0\n",
      "--------------------\n",
      "article length: 19\n",
      "Download pdf time: 12s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 66s\n",
      "Construct Pdf Tree time: 0s\n",
      "789\n"
     ]
    }
   ],
   "source": [
    "jmdata_mapping = pickle.load(open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb'))[2:]\n",
    "a = jmdPDFMap()\n",
    "P_para = []\n",
    "R_para = []\n",
    "P_sen = []\n",
    "R_sen = []\n",
    "i = 0\n",
    "for jmap in jmdata_mapping:\n",
    "    print '******************************************************'\n",
    "    print 'article ' + str(i) + ' :'\n",
    "    print '--------------------'\n",
    "    P,R = a.computePR(jmap['content'], jmap['pdf_url'], 'para')\n",
    "    P_para.append(P)\n",
    "    R_para.append(R)\n",
    "    print \"--PARA--  Pecision: \" + str(P) + \"    Recall: \" + str(R)\n",
    "    print '--------------------'\n",
    "    P,R = a.computePR(jmap['content'], jmap['pdf_url'], 'sentence')\n",
    "    P_sen.append(P)\n",
    "    R_sen.append(R)\n",
    "    print \"--SEN--  Pecision: \" + str(P) + \"    Recall: \" + str(R)\n",
    "    print '---------------------'\n",
    "    print '*******************************************************'\n",
    "    i += 1\n",
    "#print a.getIntent('前三季度利润为0，同比下降5%')['intent']\n",
    "\n",
    "# jmap = jmd_mapping[0]\n",
    "# print a.computePR(jmap['content'], jmap['pdf_url'], 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print a.get_article_sentence(jmap['content']).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666, -1, -1, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [zhuEnv2]",
   "language": "python",
   "name": "Python [zhuEnv2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

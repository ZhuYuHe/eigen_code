{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pdftree\n",
    "根节点为virtualNode，根据headline及其level构建pdftree。\n",
    "没有headline的默认为根节点的子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pdfextractor import extractor\n",
    "import pdfextractor\n",
    "import pickle\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#根据文章与pdf的映射，找出文章句子与pdf句子的匹配关系\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        return t2\n",
    "    return ''\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        s = MatchTwoText(text, pdftext, threshold)\n",
    "        if s != '':\n",
    "            return s\n",
    "    return ''\n",
    "\n",
    "#map和article中有24篇重合，24篇中有11篇有标注的\n",
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "dataJoin = dataJoin.rename(columns = {0:'文本', 1: '意图', 2: 'pdfurl'})\n",
    "pdfurls = dataJoin.pdfurl.unique()\n",
    "for url in pdfurls:\n",
    "    try :\n",
    "        pdflist = extractPDF(url, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    urldata = dataJoin[dataJoin.pdfurl == url]\n",
    "    for i in urldata.index:\n",
    "        s = isMatch(dataJoin.loc[i, '文本'], pdflist, 0.6)\n",
    "        print s\n",
    "        dataJoin.loc[i, 'pdf文本'] = s\n",
    "        \n",
    "dataJoin[dataJoin['pdf文本'] != ''].to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')\n",
    "d.columns = ['index','文本', '意图', 'pdfurl', 'pdf文本']\n",
    "d = d[d['文本'].apply(lambda x: x.__len__() > 10)]\n",
    "d = d[d['文本'].duplicated() == False]\n",
    "d.to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None,index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = \"创显将大力发展软硬件结合的教学解决方案，配套以不同层次的专业培训服务\"\n",
    "pdflist = ['2017年，公司将大力发展软硬件结合的视频教学解决方案，形成精品录播室，标准录播，配套以不同的专业培训服务', '2017年，公司将在既有的教师化信息能力平台业务基础上，进一步深化细化培养服务']\n",
    "print(isMatch(a, pdflist, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdfurl = ''\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "fileObject = open(savePath + 'jmd_pdf_map.txt', 'w') \n",
    "def write_unicode(text, charset='utf-8'):\n",
    "    return text.encode(charset)\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "#     print t1\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "#     print commonL\n",
    "#     print ct1\n",
    "#     print set(ct1).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        fileObject.write(t1.encode('utf-8'))\n",
    "        fileObject.write('\\t')\n",
    "        fileObject.write(t2.encode('utf-8'))\n",
    "        fileObject.write('\\t')\n",
    "        fileObject.write(pdfurl)\n",
    "        fileObject.write('\\n')\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        if MatchTwoText(text, pdftext, threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_node_texts(pdf_nodes):\n",
    "    '''Given a list of nodes, get the texts of these nodes\n",
    "    '''\n",
    "    texts = []\n",
    "    for node in pdf_nodes:\n",
    "        text = node.obj.get_text()\n",
    "        if len(text) <= 25:\n",
    "            continue\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "#percent: 取pdf的前多少页\n",
    "def extractPDF(pdfPath, percent, source = ['table', 'text', 'para']):\n",
    "    savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "    ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "    nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "    paraList = []\n",
    "    textList = []\n",
    "    textNodes = []\n",
    "    tableList = []\n",
    "    tableNodes = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.pdftree.VirtualNode):\n",
    "            continue\n",
    "        if isinstance(node.obj, pdfextractor.page.Table):\n",
    "            tableNodes.append(node)\n",
    "        elif  not isinstance(node.obj, pdfextractor.page.Catalog):\n",
    "            textNodes.append(node)\n",
    "    if 'table' in source:\n",
    "        tableList = get_node_texts(tableNodes)\n",
    "        tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "        #二维数组转化为一维\n",
    "        tableList = sum(tableList,[])\n",
    "    textList = get_node_texts(textNodes)\n",
    "    if 'para' in source:\n",
    "        paraList = [t.replace('\\n', '') for t in textList]\n",
    "        paraList = filter(lambda x: x != '', paraList)\n",
    "    elif 'text' in source:\n",
    "        textList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "        textList = [t.replace('\\n', '') for t in textList]\n",
    "        textList = filter(lambda x: x != '', textList)\n",
    "\n",
    "    pdf = []\n",
    "#     pdf.append(textList)\n",
    "#     pdf.append(tableList)\n",
    "#     pdf = sum(pdf, [])\n",
    "    pdf.extend(textList)\n",
    "    pdf.extend(tableList)\n",
    "    pdf.extend(paraList)\n",
    "    print pdf.__len__()\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "#     \n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt', 'w')  \n",
    "#     for text in textList:  \n",
    "#         fileObject.write(text)  \n",
    "#         fileObject.write('\\n')\n",
    "#     fileObject.close()\n",
    "#     fileObject2 = open(savePath + 'cxkjTableList.txt', 'w')  \n",
    "#     for table in tableList:  \n",
    "#         fileObject2.write(write_unicode(table))  \n",
    "#         fileObject2.write('\\n')  \n",
    "#     fileObject2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "芥末堆 5 月 1 日讯，近日，全通教育发布 2017 年第一季度财报，其营业收入为2.22 亿元，同比增长 16.45%，归属于上市公司股东的净利润为 -640.67 万元，同比减少 148.97%。 \n",
      "以 EdSaas 业务、继续教育业务、家校互动升级业务，以及学科升学业务四大业务群为核心，全通教育的业务均在稳步推进，截至报告期末： \n",
      "EdSaas 方面，作为全课云的入口，移动校园门户累计注册学校数达 16357 所，教师及家长关注数达 372 万人。 \n",
      "继续教育业务方面，“国培计划”项目陆续启动, 在巩固扩大传统优势培训项目的同时，全通继教拓展了区域性整合研修项目，针对地市县等区域性培训新需求自主进行课程研发及产品设计，取得了初步进展。 \n",
      "家校互动升级业务方面： \n",
      "成长帮手产品内容不断丰富并持续通过互联网运营增强用户活跃，已在广东、江西、浙江、河北、贵州、重庆等多个省份与基础运营商平台深度合作，加强互联网运营及线上推广，并推出“教育大咖直播课”、“专家答疑”等模块。 \n",
      "学科辅导产品全课通迭代升级，尝试在多个运营商平台深度运营，提升用户粘性，2017 年初上线的“全课答疑”不断改进答题技术及服务，截至报告期末使用用户超过 35 万； \n",
      "动力加一卡通产品运营型业务持续拓展中，报告期内新增拓展山西、甘肃、云南、青海等中西部区域，在网服务学校及用户数持续增长。同时，一季度内，公司致力于“一卡通整体解决方案” 、“和宝贝整体解决方案”、“电子学生证整体解决方案”以及“和阅卷整体解决方案”的创新和拓展。截至报告期末，\n",
      "“和宝贝”、“和阅卷”产品已取得与基础运营商全国范围合作资格。 \n",
      "对于本财季的亏损状态，全通教育解释称，原因在于其主营业务的季节性特征以及投入的增长。 \n",
      "一方面，受寒假及春节等因素影响，一季度为销售淡季，收入及成本占全年比重存在差异。 \n",
      "同时，在“十三五教育规划”的驱动下，全通教育在 2016 年内加大业务拓展与深入运营，业务覆盖较 2015 年末新增 15 个地市和重庆、天津、上海、北京 4 个直辖市，因此，本财季内，公司在人工成本、市场费用、行政费用等方面的投入较去年同期增长。 \n",
      "此外，全通教育积极申报并获批承建互联网教育系统技术及应用国家工程实验室项目，加大了在技术研发人才、研发项目推进等方面的投入。 来源：\n",
      "                                    芥末堆\n"
     ]
    }
   ],
   "source": [
    "fp = open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb')\n",
    "jmdata_mapping = pickle.load(fp)\n",
    "jmdata_mapping = jmdata_mapping[2:]\n",
    "print jmdata_mapping[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1: \n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203340942.PDF\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 48s\n",
      "Construct Pdf Tree time: 0s\n",
      "1658\n",
      "**************************\n",
      "58.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "Article 2: \n",
      "http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 69s\n",
      "Construct Pdf Tree time: 0s\n",
      "2345\n",
      "**************************\n",
      "55.5555555556% 的句子来自PDF\n",
      "***************************\n",
      "Article 3: \n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-15/601801_2016_n.pdf\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 53s\n",
      "Construct Pdf Tree time: 0s\n",
      "3614\n",
      "**************************\n",
      "41.6666666667% 的句子来自PDF\n",
      "***************************\n",
      "Article 4: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-25/1202780794.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 8s\n",
      "Construct Pdf Tree time: 0s\n",
      "494\n",
      "**************************\n",
      "64.2857142857% 的句子来自PDF\n",
      "***************************\n",
      "Article 5: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-18/1202763826.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 8s\n",
      "Construct Pdf Tree time: 0s\n",
      "450\n",
      "**************************\n",
      "37.5% 的句子来自PDF\n",
      "***************************\n",
      "Article 6: \n",
      "http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n",
      "473\n",
      "**************************\n",
      "54.5454545455% 的句子来自PDF\n",
      "***************************\n",
      "Article 7: \n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203341493.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 55s\n",
      "Construct Pdf Tree time: 0s\n",
      "2843\n",
      "**************************\n",
      "45.4545454545% 的句子来自PDF\n",
      "***************************\n",
      "Article 8: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-18/1202765393.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n",
      "466\n",
      "**************************\n",
      "28.5714285714% 的句子来自PDF\n",
      "***************************\n",
      "Article 9: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-25/1202780960.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n",
      "486\n",
      "**************************\n",
      "10.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 10: \n",
      "http://www.cninfo.com.cn/finalpage/2017-04-11/1203285646.PDF\n",
      "Download pdf time: 4s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 58s\n",
      "Article 11: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-27/1202791188.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 12s\n",
      "Construct Pdf Tree time: 0s\n",
      "564\n",
      "**************************\n",
      "55.5555555556% 的句子来自PDF\n",
      "***************************\n",
      "Article 12: \n",
      "http://disclosure.szse.cn/finalpage/2017-07-28/1203739610.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 72s\n",
      "Construct Pdf Tree time: 0s\n",
      "1844\n",
      "**************************\n",
      "58.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "Article 13: \n",
      "http://disclosure.szse.cn/finalpage/2016-04-26/1202239571.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 6s\n",
      "Construct Pdf Tree time: 0s\n",
      "363\n",
      "**************************\n",
      "0.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 14: \n",
      "http://disclosure.szse.cn/finalpage/2017-04-26/1203386046.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 9s\n",
      "Construct Pdf Tree time: 0s\n",
      "425\n",
      "**************************\n",
      "66.6666666667% 的句子来自PDF\n",
      "***************************\n",
      "Article 15: \n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-29/600661_2017_1.pdf\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 5s\n",
      "Construct Pdf Tree time: 0s\n",
      "418\n",
      "**************************\n",
      "0.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 16: \n",
      "http://www.cninfo.com.cn/finalpage/2017-06-20/1203635303.PDF\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 46s\n",
      "Construct Pdf Tree time: 0s\n",
      "2216\n",
      "**************************\n",
      "46.1538461538% 的句子来自PDF\n",
      "***************************\n",
      "Article 17: \n",
      "http://disclosure.szse.cn/finalpage/2017-08-10/1203778984.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 68s\n",
      "Construct Pdf Tree time: 0s\n",
      "2333\n",
      "**************************\n",
      "60.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 18: \n",
      "http://disclosure.szse.cn/finalpage/2017-03-28/1203210341.PDF\n",
      "Download pdf time: 8s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 70s\n",
      "Construct Pdf Tree time: 0s\n",
      "2456\n",
      "**************************\n",
      "78.9473684211% 的句子来自PDF\n",
      "***************************\n",
      "Article 19: \n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-29/600730_2017_1.pdf\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 6s\n",
      "Construct Pdf Tree time: 0s\n",
      "421\n",
      "**************************\n",
      "0.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 20: \n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2016-08-25/600661_2016_z.pdf\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 32s\n",
      "Construct Pdf Tree time: 0s\n",
      "1950\n",
      "**************************\n",
      "70.5882352941% 的句子来自PDF\n",
      "***************************\n",
      "Article 21: \n",
      "http://www.cninfo.com.cn/finalpage/2017-07-28/1203751786.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 24s\n",
      "Construct Pdf Tree time: 0s\n",
      "1625\n",
      "**************************\n",
      "31.8181818182% 的句子来自PDF\n",
      "***************************\n",
      "Article 22: \n",
      "http://disclosure.szse.cn/finalpage/2017-04-25/1203379575.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 68s\n",
      "Construct Pdf Tree time: 1s\n",
      "2369\n",
      "**************************\n",
      "76.9230769231% 的句子来自PDF\n",
      "***************************\n",
      "Article 23: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 13s\n",
      "Construct Pdf Tree time: 0s\n",
      "491\n",
      "**************************\n",
      "28.5714285714% 的句子来自PDF\n",
      "***************************\n",
      "Article 24: \n",
      "http://www.cninfo.com.cn/finalpage/2017-05-10/1203508904.PDF\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 46s\n",
      "Construct Pdf Tree time: 0s\n",
      "2795\n",
      "**************************\n",
      "77.7777777778% 的句子来自PDF\n",
      "***************************\n",
      "Article 25: \n",
      "http://disclosure.szse.cn/finalpage/2017-04-24/1203360123.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 77s\n",
      "Construct Pdf Tree time: 0s\n",
      "2621\n",
      "**************************\n",
      "47.0588235294% 的句子来自PDF\n",
      "***************************\n",
      "Article 26: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-29/1202801424.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 8s\n",
      "Construct Pdf Tree time: 0s\n",
      "453\n",
      "**************************\n",
      "7.69230769231% 的句子来自PDF\n",
      "***************************\n",
      "Article 27: \n",
      "http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 47s\n",
      "Construct Pdf Tree time: 0s\n",
      "2334\n",
      "**************************\n",
      "58.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "Article 28: \n",
      "http://disclosure.szse.cn/finalpage/2017-03-18/1203174359.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 51s\n",
      "Construct Pdf Tree time: 0s\n",
      "2577\n",
      "**************************\n",
      "40.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 29: \n",
      "http://disclosure.szse.cn/finalpage/2017-08-25/1203872097.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 51s\n",
      "Construct Pdf Tree time: 0s\n",
      "1930\n",
      "**************************\n",
      "25.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 30: \n",
      "http://disclosure.szse.cn/finalpage/2016-04-30/1202283035.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 7s\n",
      "Construct Pdf Tree time: 0s\n",
      "373\n",
      "**************************\n",
      "0.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 31: \n",
      "http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 35s\n",
      "Construct Pdf Tree time: 0s\n",
      "1974\n",
      "**************************\n",
      "61.5384615385% 的句子来自PDF\n",
      "***************************\n",
      "Article 32: \n",
      "http://www.cninfo.com.cn/finalpage/2017-07-26/1203737887.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 24s\n",
      "Construct Pdf Tree time: 0s\n",
      "1529\n",
      "**************************\n",
      "50.0% 的句子来自PDF\n",
      "***************************\n",
      "Article 33: \n",
      "http://disclosure.szse.cn/finalpage/2017-03-21/1203181705.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 100s\n",
      "Construct Pdf Tree time: 0s\n",
      "2873\n",
      "**************************\n",
      "66.6666666667% 的句子来自PDF\n",
      "***************************\n",
      "Article 34: \n",
      "http://disclosure.szse.cn/finalpage/2016-10-26/1202785562.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 8s\n",
      "Construct Pdf Tree time: 0s\n",
      "514\n",
      "**************************\n",
      "42.8571428571% 的句子来自PDF\n",
      "***************************\n",
      "Article 35: \n",
      "http://disclosure.szse.cn/finalpage/2017-04-11/1203274908.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 72s\n",
      "Construct Pdf Tree time: 0s\n",
      "2084\n",
      "**************************\n",
      "69.2307692308% 的句子来自PDF\n",
      "***************************\n",
      "Article 36: \n",
      "http://disclosure.szse.cn/finalpage/2016-08-26/1202622898.PDF\n",
      "Download pdf time: 4s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 46s\n",
      "Construct Pdf Tree time: 0s\n",
      "1732\n",
      "**************************\n",
      "22.2222222222% 的句子来自PDF\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "fp = open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb')\n",
    "jmdata_mapping = pickle.load(fp)\n",
    "\n",
    "content_url_map = {}\n",
    "for d in jmdata_mapping[2:]:\n",
    "    content_url_map[d['pdf_url']] = d['content']\n",
    "\n",
    "urls = content_url_map.keys()\n",
    "\n",
    "num = 1\n",
    "result = {}\n",
    " \n",
    "\n",
    "for path in urls:\n",
    "    print \"Article \" + str(num) + \": \" \n",
    "    num += 1\n",
    "    \n",
    "    print path\n",
    "    pdfurl = path\n",
    "    \n",
    "    cxkj = content_url_map[path]\n",
    "    #print cxkj\n",
    "    cxkj = cxkj.strip().encode('utf-8').split('。')\n",
    "    cxkj = [x.replace('\\n','') for x in cxkj]\n",
    "    try :\n",
    "        pdflist = extractPDF(path, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    \n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt')\n",
    "#     textlist = fileObject.read().split('\\n')\n",
    "#     fileObject = open(savePath + 'cxkjTableList.txt')\n",
    "#     tablelist = fileObject.read().split('\\n')\n",
    "#     fileObject.close()\n",
    "\n",
    "#     PDFTextList = []\n",
    "#     PDFTextList.append(textlist)\n",
    "#     PDFTextList.append(tablelist)\n",
    "#     PDFTextList = sum(PDFTextList, [])\n",
    "#     print PDFTextList.__len__()\n",
    "    print('**************************')\n",
    "    count = 0\n",
    "    for text in cxkj:\n",
    "        if not (len(text) == 0):\n",
    "            if isMatch(text, pdflist, 0.6):\n",
    "                count+=1\n",
    "    print str(count * 1.0/ cxkj.__len__() * 100) + '% 的句子来自PDF'\n",
    "    result[path] = count * 1.0/ cxkj.__len__() * 100\n",
    "    print('***************************')\n",
    "    \n",
    "fileObject.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']['pdf文本']\n",
    "pdftext.to_csv('/home/zhuyuhe/mydata/jmd/predict/pdftext.txt', header = None, index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#计算pdf意图符合文章意图的句子比例\n",
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']\n",
    "pdftext_intent = pd.read_csv('/home/zhuyuhe/mydata/jmd/predict/cxkjpdftext_predict.txt', header = None)\n",
    "pdftext['pdfintent'] = pdftext_intent.values\n",
    "pdftext['pdfintent'] = pdftext['pdfintent'].apply(lambda x: x.replace('__label__', ''))\n",
    "pdftext['意图'] = pdftext['意图'].apply(lambda x: '|'.join(x.split('|')[:2]))\n",
    "bol = pdftext['意图'] == pdftext['pdfintent']\n",
    "print \"文本句子有 \" + str(len(bol)) + \" 句\"\n",
    "print \"pdf意图符合文章意图的句子比例为\" + str(bol.value_counts()[1] * 1.0 / len(bol) * 100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print qtjypdftext[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = np.array(result.values())\n",
    "result[result != 0]\n",
    "#0%的原因： 1.科大讯飞  -  表格描述；上一季度财报描述  ×2 \n",
    "#           2.新南洋    -  财报中大部分均为表格，并且文章使用了其他季度的财报\n",
    "#           3.中国高科  -  前两句话描述财报表格，\n",
    "#           4.洪涛股份  -  文章与财报不匹配，2015年年报 = 2016年第一季度财报？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    if isinstance(n.obj, pdfextractor.pdftree.VirtualNode):\n",
    "        continue\n",
    "    if len(n.obj.get_text()) <= 25:\n",
    "        continue\n",
    "    else:\n",
    "        text = n.obj.get_text()\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        text_nodes.append(n)\n",
    "        print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "node= text_nodes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isinstance(node.obj,pdfextractor.paragraph.Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_child_headlines(pdf_node):\n",
    "    '''Get headlines of children of a node\n",
    "    '''\n",
    "    headlines = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline):\n",
    "            headlines.append(node)\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_child_paragraphs(pdf_node):\n",
    "    '''Get paragraphs of children of a node\n",
    "    '''\n",
    "    paragraphs = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "            paragraphs.append(node)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_paragraph_headlines(pdf_node):\n",
    "    '''Get headlines of a paragraph\n",
    "    Input:\n",
    "        - pdf_node: a pdf node\n",
    "    Output:\n",
    "        - headlines: a list of sorted headline nodes\n",
    "        - texts: a list of sorted headline texts\n",
    "    '''\n",
    "    headlines = []\n",
    "    node = pdf_node.parent\n",
    "    while not isinstance(node.obj,pdfextractor.pdftree.VirtualNode):\n",
    "        headlines.append(node)\n",
    "        node = node.parent\n",
    "    headlines = list(reversed(headlines))\n",
    "    return headlines, get_node_texts(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print get_paragraph_headlines(text_nodes[15])[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "host = 'https://alpha-surreal.aidigger.com/api/v1/classification/intent/finance/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hd_intents = []\n",
    "all_intents = []\n",
    "for node in text_nodes:\n",
    "    content = node.obj.get_text()\n",
    "    headline = get_paragraph_headlines(node)[1][-1]\n",
    "    intents = requests.post(host,json={\"query\":content}).json()\n",
    "    head_intents = requests.post(host,json={\"query\":headline}).json()\n",
    "    for i,item in enumerate(head_intents['predict']):\n",
    "        intents['predict'][i]['prob'] += item['prob']\n",
    "    all_intents.append(intents)\n",
    "    intent = max(intents['predict'],key=lambda item:item['prob'])\n",
    "    hd_intents.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_intent(it):\n",
    "    for i,item in enumerate(it):\n",
    "        print i,item['name'],item['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_intent(all_intents[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,intent in enumerate(hd_intents):\n",
    "    print i\n",
    "    print text_nodes[i]\n",
    "    print ' ==> '.join(get_paragraph_headlines(text_nodes[i])[1])\n",
    "    print intent['name'],'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据芥末堆提供的意图模板，得到意图推荐的准确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = requests.post(\"https://surreal.aidigger.com/api/v1/classification/intent/finance/0\",json={ \n",
    "    \"query\": \"公司立足校园、面向家庭提供教育信息服务，深耕教育十余年已形成覆盖校内外多场景、涵盖教育主管部门、学校、教师、家长及学生等 B 端、C 端主体的业务服务体系。公司针对不同用户群体多场景、多元化需求，持续优化服务供给，逐步构建了家校互动升级业务、EdSaaS 业务、学科升学业务及继续教育业务，报告期内公司主营业务未发生变化。\"\n",
    "}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasCN(s):\n",
    "    \"\"\"\n",
    "    判断一段文本是否有中文\n",
    "    \"\"\"\n",
    "    for ch in s.decode('utf-8'):\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "\n",
    "dataJoin.columns = ['文本', '意图', 'pdfurl']\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: len(x) > 30)]\n",
    "dataJoin = dataJoin[dataJoin['文本'].duplicated() == False]\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: hasCN(x))]\n",
    "\n",
    "dataJoin.index = range(len(dataJoin))\n",
    "dataJoin['意图'] = dataJoin['意图'].apply(lambda x: intentMap(x))\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['意图'].apply(lambda x: x!= 'Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "业绩变动原因\n",
      "主营业务$业务进展\n",
      "导语\n",
      "未来计划\n"
     ]
    }
   ],
   "source": [
    "for i in dataJoin['意图'].unique():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其中和晶互联网教育参股子公司环宇万维，持有其34.43%的股权。\n"
     ]
    }
   ],
   "source": [
    "a = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202791188.PDF']\n",
    "b = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-25/1202780960.PDF'] \n",
    "c = dataJoin[dataJoin.pdfurl == 'http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF']\n",
    "print a.loc[119, '文本']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataJoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未来计划         14\n",
      "主营业务$业务进展    12\n",
      "业绩变动原因        8\n",
      "导语            7\n",
      "Name: 意图, dtype: int64\n",
      "导语           2\n",
      "主营业务$业务进展    2\n",
      "Name: 意图, dtype: int64\n",
      "主营业务$业务进展    5\n",
      "导语           1\n",
      "业绩变动原因       1\n",
      "未来计划         1\n",
      "Name: 意图, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print a['意图'].value_counts()\n",
    "print b['意图'].value_counts()\n",
    "print c['意图'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [zhuEnv2]",
   "language": "python",
   "name": "Python [zhuEnv2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

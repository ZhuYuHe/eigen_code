{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pdftree\n",
    "根节点为virtualNode，根据headline及其level构建pdftree。\n",
    "没有headline的默认为根节点的子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pdfextractor import extractor\n",
    "import pdfextractor\n",
    "import pickle\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#根据文章与pdf的映射，找出文章句子与pdf句子的匹配关系\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "        return t2\n",
    "    return ''\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        s = MatchTwoText(text, pdftext, threshold)\n",
    "        if s != '':\n",
    "            return s\n",
    "    return ''\n",
    "\n",
    "#map和article中有24篇重合，24篇中有11篇有标注的\n",
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "dataJoin = dataJoin.rename(columns = {0:'文本', 1: '意图', 2: 'pdfurl'})\n",
    "pdfurls = dataJoin.pdfurl.unique()\n",
    "for url in pdfurls:\n",
    "    try :\n",
    "        pdflist = extractPDF(url, 0.8)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    urldata = dataJoin[dataJoin.pdfurl == url]\n",
    "    for i in urldata.index:\n",
    "        s = isMatch(dataJoin.loc[i, '文本'], pdflist, 0.6)\n",
    "        print s\n",
    "        dataJoin.loc[i, 'pdf文本'] = s\n",
    "        \n",
    "dataJoin[dataJoin['pdf文本'] != ''].to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None, sep = '\\t', encoding = 'utf-8')\n",
    "d.columns = ['index','文本', '意图', 'pdfurl', 'pdf文本']\n",
    "d = d[d['文本'].apply(lambda x: x.__len__() > 10)]\n",
    "d = d[d['文本'].duplicated() == False]\n",
    "d.to_csv('/home/zhuyuhe/mydata/jmd/percent/jmd_text_map.txt', header = None,index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = \"创显将大力发展软硬件结合的教学解决方案，配套以不同层次的专业培训服务\"\n",
    "pdflist = ['2017年，公司将大力发展软硬件结合的视频教学解决方案，形成精品录播室，标准录播，配套以不同的专业培训服务', '2017年，公司将在既有的教师化信息能力平台业务基础上，进一步深化细化培养服务']\n",
    "print(isMatch(a, pdflist, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdfurl = ''\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "# fileObject = open(savePath + 'jmd_pdf_map.txt', 'w') \n",
    "def write_unicode(text, charset='utf-8'):\n",
    "    return text.encode(charset)\n",
    "def MatchTwoText(t1, t2, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    检查两个句子是否匹配\n",
    "    \"\"\"\n",
    "#     print t1\n",
    "    ct1 = ' '.join(jieba.cut(t1)).split()\n",
    "    ct2 = ' '.join(jieba.cut(t2)).split()\n",
    "    commonL = set(ct1).intersection(set(ct2)).__len__()\n",
    "#     print commonL\n",
    "#     print ct1\n",
    "#     print set(ct1).__len__()\n",
    "    if commonL * 1.0 / set(ct1).__len__() > threshold:\n",
    "#         print(\"match \" + str(commonL * 1.0/ set(ct1).__len__() * 100) + '% ')\n",
    "#         print(\"文章句子:\" + '\\n' + t1)\n",
    "#         print(\"PDF句子: \" + '\\n' + t2)\n",
    "#         print('\\n')\n",
    "#         fileObject.write(t1.encode('utf-8'))\n",
    "#         fileObject.write('\\t')\n",
    "#         fileObject.write(t2.encode('utf-8'))\n",
    "#         fileObject.write('\\t')\n",
    "#         fileObject.write(pdfurl)\n",
    "#         fileObject.write('\\n')\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def isMatch(text, pdfTextList, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    @parameter text: 待检查句子\n",
    "    @parameter pdfTextList: PDF句子与表格信息列表\n",
    "    @parameter threshold: 相似度为多少时返回true\n",
    "    @return： boolean值，pdf列表中是否有与待检查句子非常相似的句子\n",
    "    \"\"\"\n",
    "    for pdftext in pdfTextList:\n",
    "        if MatchTwoText(text, pdftext, threshold):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_node_texts(pdf_nodes):\n",
    "    '''Given a list of nodes, get the texts of these nodes\n",
    "    '''\n",
    "    texts = []\n",
    "    for node in pdf_nodes:\n",
    "        text = node.obj.get_text()\n",
    "        if len(text) <= 25:\n",
    "            continue\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "#percent: 取pdf的前多少页\n",
    "def extractPDF(pdfPath, percent, source = ['table', 'text', 'para'], headline = None):\n",
    "    savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "    ex = extractor.StockFinanceExtractor(pdfPath, percent)\n",
    "\n",
    "    nodes = ex.get_pdf_objects(filter_headline=True)\n",
    "\n",
    "    paraList = []\n",
    "    textList = []\n",
    "    textNodes = []\n",
    "    tableList = []\n",
    "    tableNodes = []\n",
    "    senList = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.pdftree.VirtualNode):\n",
    "            continue\n",
    "        if isinstance(node.obj, pdfextractor.page.Table):\n",
    "            tableNodes.append(node)\n",
    "        elif  not isinstance(node.obj, pdfextractor.page.Catalog):\n",
    "            textNodes.append(node)\n",
    "    if 'table' in source:\n",
    "        tableList = get_node_texts(tableNodes)\n",
    "        tableList = [t.replace('|', '').split('\\n') for t in tableList]\n",
    "        #二维数组转化为一维\n",
    "        tableList = sum(tableList,[])\n",
    "    textList = get_node_texts(textNodes)\n",
    "    if 'para' in source:\n",
    "        paraList = [t.replace('\\n', '') for t in textList]\n",
    "        paraList = filter(lambda x: x != '', paraList)\n",
    "    elif 'text' in source:\n",
    "        senList = sum([t.encode('utf-8').split('。') for t in textList],[])\n",
    "        senList = [t.replace('\\n', '') for t in senList]\n",
    "        senList = filter(lambda x: x != '', senList)\n",
    "\n",
    "    pdf = []\n",
    "#     pdf.append(textList)\n",
    "#     pdf.append(tableList)\n",
    "#     pdf = sum(pdf, [])\n",
    "    pdf.extend(senList)\n",
    "    pdf.extend(tableList)\n",
    "    pdf.extend(paraList)\n",
    "    print pdf.__len__()\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "\n",
    "#     \n",
    "#     fileObject = open(savePath + 'cxkjTextList.txt', 'w')  \n",
    "#     for text in textList:  \n",
    "#         fileObject.write(text)  \n",
    "#         fileObject.write('\\n')\n",
    "#     fileObject.close()\n",
    "#     fileObject2 = open(savePath + 'cxkjTableList.txt', 'w')  \n",
    "#     for table in tableList:  \n",
    "#         fileObject2.write(write_unicode(table))  \n",
    "#         fileObject2.write('\\n')  \n",
    "#     fileObject2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print MatchTwoText('报告显示，方直科技在一季度实现营业收入34,743,435.23元，由于教育系统征订销售收入和其他产品销售收入的增加，营收同比增长5.48%。',\n",
    "                   '公司在2016年第一季度实现营业收入34,743,435.23元 ，营业收入较上年同期增长5.48%，主要来自于教育系统征订销售收入增加和其他产品销售收入增加。公司核心产品业务及其结构未发生重大变化，金太阳教育软件的开发、销售业务仍是公司的核心业务。华南、华北和华东三个地区是公司产品销售比较集中的区域，报告期内各地区销售收入占主营业务收入比例分别为 70.48%、16.55%、7.2%。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://disclosure.szse.cn/finalpage/2016-10-25/1202780794.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct Pdf Tree time: 0s\n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.374 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.2857142857% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 7s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "63.6363636364% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 10s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "28.5714285714% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-26/1203386046.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 5s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203340942.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 20s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 50s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "66.6666666667% 的句子来自PDF\n",
      "***************************\n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-15/601801_2016_n.pdf\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 42s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "58.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-07-28/1203739610.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 60s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "50.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-06-20/1203635303.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 40s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "61.5384615385% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-08-10/1203778984.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 51s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "53.3333333333% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-28/1203210341.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 60s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "78.9473684211% 的句子来自PDF\n",
      "***************************\n",
      "http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2016-08-25/600661_2016_z.pdf\n",
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 22s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.4705882353% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-07-28/1203751786.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 16s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "31.8181818182% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-25/1203379575.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.9230769231% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-05-10/1203508904.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 37s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "81.4814814815% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-24/1203360123.PDF\n",
      "Download pdf time: 32s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 49s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "47.0588235294% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-18/1203174359.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "60.0% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-19/1203341493.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 44s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "54.5454545455% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF\n",
      "Download pdf time: 1s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 22s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "69.2307692308% 的句子来自PDF\n",
      "***************************\n",
      "http://www.cninfo.com.cn/finalpage/2017-07-26/1203737887.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 18s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "75.0% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-03-21/1203181705.PDF\n",
      "Download pdf time: 3s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 69s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.1904761905% 的句子来自PDF\n",
      "***************************\n",
      "http://disclosure.szse.cn/finalpage/2017-04-11/1203274908.PDF\n",
      "Download pdf time: 2s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 38s\n",
      "Construct Pdf Tree time: 0s\n",
      "------\n",
      "76.9230769231% 的句子来自PDF\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "#根据pdfurl和文章内容，找出每篇文章有多大比例来自pdf。并将pdf的段落保存下来\n",
    "import sys\n",
    "import pickle\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "seasonArticle = ['http://disclosure.szse.cn/finalpage/2016-10-25/1202780794.PDF', 'http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF', 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF','http://disclosure.szse.cn/finalpage/2017-04-26/1203386046.PDF']\n",
    "yearlyArticle = [u'http://www.cninfo.com.cn/finalpage/2017-04-19/1203340942.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF',\n",
    "                 u'http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-04-15/601801_2016_n.pdf', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-07-28/1203739610.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-06-20/1203635303.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-08-10/1203778984.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-28/1203210341.PDF', \n",
    "                 u'http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2016-08-25/600661_2016_z.pdf', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-07-28/1203751786.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-25/1203379575.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-05-10/1203508904.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-24/1203360123.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF', \n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-18/1203174359.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-19/1203341493.PDF', \n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-04-21/1203369775.PDF',\n",
    "                 u'http://www.cninfo.com.cn/finalpage/2017-07-26/1203737887.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-03-21/1203181705.PDF',\n",
    "                 u'http://disclosure.szse.cn/finalpage/2017-04-11/1203274908.PDF']\n",
    "\n",
    "def splitByPeriod(P):\n",
    "    \"\"\"\n",
    "    split paragraph to sentences\n",
    "    \"\"\"\n",
    "    senList = sum([t.encode('utf-8').split('。') for t in P],[])\n",
    "    senList = [t.replace('\\n', '') for t in senList]\n",
    "    senList = filter(lambda x: x != '', senList)\n",
    "    return senList\n",
    "\n",
    "savePath = '/home/zhuyuhe/mydata/jmd/percent/'\n",
    "# fp = open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_mapping2.pkl', 'rb')\n",
    "fp = open('/home/zhuyuhe/mydata/jmd/jmt_jmd_mappings2.pkl', 'rb')\n",
    "jmdata_mapping = pickle.load(fp)\n",
    "\n",
    "content_url_map = {}\n",
    "for d in jmdata_mapping:\n",
    "    content_url_map[d['pdf_url']] = d['content']\n",
    "\n",
    "urls = content_url_map.keys()\n",
    "\n",
    "num = 1\n",
    "result = {}\n",
    "jmdata_map_headline = {}\n",
    "\n",
    "def parsePDF(urls,style, cond):  \n",
    "    jmdata_map_headline[style] = {}\n",
    "    for pdfurl in urls:\n",
    "        print pdfurl\n",
    "        jmdata_map_headline[style][pdfurl] = {}\n",
    "\n",
    "        cxkj = content_url_map[pdfurl]\n",
    "        #print cxkj\n",
    "        cxkj = cxkj.strip().encode('utf-8').split('。')\n",
    "        cxkj = [x.replace('\\n','') for x in cxkj]\n",
    "\n",
    "        try :\n",
    "            pdflist = getPara(pdfurl, 0.5, cond)\n",
    "        except BaseException:\n",
    "            print 'error extractPDF'\n",
    "            continue\n",
    "\n",
    "        print \"------\"\n",
    "        jmdata_map_headline[style][pdfurl]['content'] = cxkj\n",
    "        jmdata_map_headline[style][pdfurl]['para'] = pdflist\n",
    "        jmdata_map_headline[style][pdfurl]['sen'] = splitByPeriod(pdflist)\n",
    "        jmdata_map_headline[style][pdfurl]['mapcontent'] = []\n",
    "#         for i in cxkj:\n",
    "#             print i\n",
    "#             print '-'\n",
    "#         print '**********'\n",
    "#         for i in pdflist:\n",
    "#             print i\n",
    "#             print '-'\n",
    "\n",
    "    #     fileObject = open(savePath + 'cxkjTextList.txt')\n",
    "    #     textlist = fileObject.read().split('\\n')\n",
    "    #     fileObject = open(savePath + 'cxkjTableList.txt')\n",
    "    #     tablelist = fileObject.read().split('\\n')\n",
    "    #     fileObject.close()\n",
    "\n",
    "    #     PDFTextList = []\n",
    "    #     PDFTextList.append(textlist)\n",
    "    #     PDFTextList.append(tablelist)\n",
    "    #     PDFTextList = sum(PDFTextList, [])\n",
    "    #     print PDFTextList.__len__()\n",
    "        count = 0\n",
    "        for text in cxkj:\n",
    "            if not (len(text) == 0):\n",
    "                if isMatch(text, pdflist, 0.6):\n",
    "                    jmdata_map_headline[style][pdfurl]['mapcontent'].append(text)\n",
    "                    count+=1\n",
    "\n",
    "        print str(count * 1.0/ cxkj.__len__() * 100) + '% 的句子来自PDF'\n",
    "        result[pdfurl] = count * 1.0/ cxkj.__len__() * 100\n",
    "        print('***************************')\n",
    "    \n",
    "# fileObject.close()\n",
    "\n",
    "parsePDF(seasonArticle, 'season', ['重大风险提示', '业务回顾和展望'])\n",
    "parsePDF(yearlyArticle, 'year', ['讨论与分析', '公司业务概要'])\n",
    "\n",
    "#parsePDF(['http://disclosure.szse.cn/finalpage/2016-04-26/1202239317.PDF'], 'season', ['重大风险提示', '业务回顾和展望'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日傍晚， 方直科技 （300235）发布了2016年第三季度报告，报告显示，2016年第三季度，其营业总收入为3610.01万元，归属于上市公司股东的净利润为1331.05万元\n",
      "--\n",
      " 营收数据 统计数据显示，截至报告期末，方直科技总资产为3.80亿元\n",
      "--\n",
      "其第三季度营业总收入为3610.01万元，同比下降14.40%；归属于上市公司股东的净利润为1331.05万元，同比增加5.20%\n",
      "--\n",
      " 2016年前三季度，方直科技营业总收入为7936.14万元，同比下降2.89%；归属于上市公司股东的净利润为1817.50万元，同比下降22.32% 据悉，本报告期末应收账款比年初增长108.12%，主要原因是秋季教育系统征订业务确认收入形成的应收账款较大所致\n",
      "--\n",
      " 业务展望 前三季度，方直科技核心产品业务及其结构未发生重大变化，金太阳教育软件的开发、销售业务仍是公司的核心业务\n",
      "--\n",
      "华南、华北和华东三个地区是产品销售比较集中的区域，报告期内各地区销售收入占主营业务收入比例分别为67.08%、17.92%、8.6%\n",
      "--\n",
      " 未来，在产品研发方面，方直科技将继续巩固强化公司在内容资源方面的优势，建立和完善语文、英语、数学等多学科、多版本的同步教学优质资源开发\n",
      "--\n",
      "不断丰富金太阳产品集群多样性，加快推进各应用端全覆盖，促使更多的免费使用用户转化为购买用户\n",
      "--\n",
      " 另一方面，方直科技将不断加大对网络技术开发、学习资源开发及网络产品运营人力的投入，以加速向互联网企业转型\n",
      "--\n",
      " 风险应对 目前方直科技的销售区域仍主要以珠三角、长三角及京津地区等大中城市为主，市场区域相对集中并存在一定风险，可能对其未来盈利能力造成影响\n",
      "--\n",
      " 方直科技将通过技术研发和产品拓展计划、营销渠道拓展计划解决上述产品及销售区域较为集中的风险\n",
      "--\n",
      " 如果方直科技对行业关键技术的发展动态不能及时掌控，对教育教学当中的新理念以及广大教师和学生的教学需求不能正确把握，研发的产品将不具备竞争力\n",
      "--\n",
      " 因此，方直科技将积极投入同步教学软件及在线教育网络服务开发平台的开发，加强基础教育项目研究\n",
      "--\n",
      " 来源：                                    芥末堆\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "k = seasonArticle[0]\n",
    "for i in jmdata_map_headline['season'][k]['content']:\n",
    "    print i\n",
    "    print '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPara(pdfurl, percent = 0.5, cond = ['业务回顾和展望', '重大风险提示']):\n",
    "    ex = extractor.StockFinanceExtractor(pdfurl, percent)\n",
    "    nodes = ex.get_pdf_objects()\n",
    "    headlines = getHeadlines(nodes, 5)\n",
    "#     print 'headlines length : ' + str(len(headlines))\n",
    "    targethl = []\n",
    "    res = []\n",
    "    for hl in headlines:\n",
    "        for c in cond:\n",
    "            if c in hl.obj.get_text():\n",
    "                targethl.append(hl)\n",
    "#     print 'targethl :' + str(len(targethl))\n",
    "#     for t in targethl:\n",
    "#         print t.obj.get_text()\n",
    "    if len(targethl) == 0:\n",
    "        paraList = []\n",
    "        for node in nodes:\n",
    "            if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "                paraList.append(node.obj.get_text())\n",
    "        return paraList\n",
    "\n",
    "    for t in targethl:\n",
    "        res.extend(get_para_recu(t))\n",
    "    return res\n",
    "    \n",
    "def get_para_recu(node):\n",
    "    res = []\n",
    "    if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "        return res\n",
    "    child_headlines = get_child_headlines(node)\n",
    "    child_paras = get_child_paragraphs(node)\n",
    "    for c in child_paras:\n",
    "        res.append(filter_text(c.obj.get_text()))\n",
    "    for c in child_headlines:\n",
    "        res.extend(get_para_recu(c))\n",
    "    return res\n",
    "\n",
    "def filter_text(text):\n",
    "    if len(text) <= 25:\n",
    "        return ''\n",
    "    if u'□' in text or u'√' in text:\n",
    "        return ''\n",
    "    return text\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def get_child_headlines(pdf_node):\n",
    "    '''Get headlines of children of a node\n",
    "    '''\n",
    "    headlines = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline):\n",
    "            headlines.append(node)\n",
    "    return headlines\n",
    "\n",
    "def get_child_paragraphs(pdf_node):\n",
    "    '''Get paragraphs of children of a node\n",
    "    '''\n",
    "    paragraphs = []\n",
    "    for node in pdf_node.children:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Paragraph):\n",
    "            paragraphs.append(node)\n",
    "    return paragraphs\n",
    "\n",
    "def getHeadlines(nodes, level):\n",
    "    \"\"\"\n",
    "    return headline-nodes from given nodes\n",
    "    \"\"\"\n",
    "    re = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline) and node.obj.level <= level:\n",
    "            re.append(node)\n",
    "    return re\n",
    "\n",
    "def getMaxLevel():\n",
    "    pass\n",
    "        \n",
    "        \n",
    "             \n",
    "\n",
    "# target = getTargetNode()\n",
    "\n",
    "# print get_child_paragraphs(get_child_headlines(get_child_headlines(target)[0])[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "12\n",
      "145\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['content'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['mapcontent'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['para'])\n",
    "print len(jmdata_map['http://disclosure.szse.cn/finalpage/2017-04-21/1203344261.PDF']['sen'])\n",
    "jmdata_map = dict(filter(lambda x: len(x[1]) != 0, jmdata_map.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_map_headline.pkl', 'wb') as pickle_file:\n",
    "     pickle.dump(jmdata_map_headline, pickle_file , protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/zhuyuhe/mydata/jmd/percent/jmd_pdf_map.pkl', 'wb') as pickle_file:\n",
    "     pickle.dump(jmdata_map, pickle_file , protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']['pdf文本']\n",
    "pdftext.to_csv('/home/zhuyuhe/mydata/jmd/predict/pdftext.txt', header = None, index=None, sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#计算pdf意图符合文章意图的句子比例\n",
    "pdftext = dataJoin[dataJoin['pdfurl'] == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202793355.PDF'][dataJoin['pdf文本'] != '']\n",
    "pdftext_intent = pd.read_csv('/home/zhuyuhe/mydata/jmd/predict/cxkjpdftext_predict.txt', header = None)\n",
    "pdftext['pdfintent'] = pdftext_intent.values\n",
    "pdftext['pdfintent'] = pdftext['pdfintent'].apply(lambda x: x.replace('__label__', ''))\n",
    "pdftext['意图'] = pdftext['意图'].apply(lambda x: '|'.join(x.split('|')[:2]))\n",
    "bol = pdftext['意图'] == pdftext['pdfintent']\n",
    "print \"文本句子有 \" + str(len(bol)) + \" 句\"\n",
    "print \"pdf意图符合文章意图的句子比例为\" + str(bol.value_counts()[1] * 1.0 / len(bol) * 100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print qtjypdftext[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = np.array(result.values())\n",
    "result[result != 0]\n",
    "#0%的原因： 1.科大讯飞  -  表格描述；上一季度财报描述  ×2 \n",
    "#           2.新南洋    -  财报中大部分均为表格，并且文章使用了其他季度的财报\n",
    "#           3.中国高科  -  前两句话描述财报表格，\n",
    "#           4.洪涛股份  -  文章与财报不匹配，2015年年报 = 2016年第一季度财报？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    if isinstance(n.obj, pdfextractor.pdftree.VirtualNode):\n",
    "        continue\n",
    "    if len(n.obj.get_text()) <= 25:\n",
    "        continue\n",
    "    else:\n",
    "        text = n.obj.get_text()\n",
    "        if u'□' in text or u'√' in text:\n",
    "            continue\n",
    "        text_nodes.append(n)\n",
    "        print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "node= text_nodes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isinstance(node.obj,pdfextractor.paragraph.Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download pdf time: 0s\n",
      "download http status code: 200\n",
      "Pdfminer Parsed time: 3s\n",
      "Construct Pdf Tree time: 0s\n"
     ]
    }
   ],
   "source": [
    "#抽出特定条件下（headline）的段落\n",
    "ex = extractor.StockFinanceExtractor('http://www.cninfo.com.cn/finalpage/2017-04-29/1203425130.PDF', 0.5)\n",
    "\n",
    "nodes = ex.get_pdf_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zhuyuhe', 'shenjiajia']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['zhu'+'yuhe', 'shenjiajia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 年第一季度报告\n"
     ]
    }
   ],
   "source": [
    "print nodes[2].obj.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_table_nodes(nodes):\n",
    "    tables = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.table.Table):\n",
    "            tables.append(node)\n",
    "    return tables\n",
    "def get_headline_nodes(nodes):\n",
    "    headlines = []\n",
    "    for node in nodes:\n",
    "        if isinstance(node.obj, pdfextractor.paragraph.Headline):\n",
    "            headlines.append(node)\n",
    "    return headlines\n",
    "def get_paragraph_headlines(pdf_node):\n",
    "    '''Get headlines of a paragraph\n",
    "    Input:\n",
    "        - pdf_node: a pdf node\n",
    "    Output:\n",
    "        - headlines: a list of sorted headline nodes\n",
    "        - texts: a list of sorted headline texts\n",
    "    '''\n",
    "    headlines = []\n",
    "    node = pdf_node.parent\n",
    "    while not isinstance(node.obj,pdfextractor.pdftree.VirtualNode):\n",
    "        headlines.append(node)\n",
    "        node = node.parent\n",
    "    headlines = list(reversed(headlines))\n",
    "    return headlines, get_node_texts(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u' ', u'\\u672c\\u62a5\\u544a\\u671f ', u'\\u4e0a\\u5e74\\u540c\\u671f ', u'\\u672c\\u62a5\\u544a\\u671f\\u6bd4\\u4e0a\\u5e74\\u540c\\u671f\\u589e\\u51cf'], [u'\\u8425\\u4e1a\\u6536\\u5165\\uff08\\u5143\\uff09 ', u'4,412,184,212.16', u' 3,543,649,778.82', u' 24.51'], [u'\\u5f52\\u5c5e\\u4e8e\\u4e0a\\u5e02\\u516c\\u53f8\\u80a1\\u4e1c\\u7684\\u51c0\\u5229\\u6da6\\uff08\\u5143\\uff09 ', u'230,667,840.43', u' 321,923,477.66', u' -28.35']]\n"
     ]
    }
   ],
   "source": [
    "tablenodes = get_table_nodes(nodes)\n",
    "def get_table_column_name(node):\n",
    "    if not isinstance(node.obj, pdfextractor.table.Table):\n",
    "        raise TypeError(\"node is not a table object\")\n",
    "    return node.obj.get_text().split('\\n')[0].split('|')\n",
    "def get_table_info(node, match = None, col_cond = None):\n",
    "        \"\"\"\n",
    "        return the table content match the given condition\n",
    "        \"\"\"\n",
    "        content = []\n",
    "        if not isinstance(node.obj, pdfextractor.table.Table):\n",
    "            raise TypeError(\"node is not a table object\")\n",
    "        if match is None:\n",
    "            return content\n",
    "        if not (type(match) == list):\n",
    "            raise TypeError(\"parameter 'match' should be list type\")\n",
    "        if (not col_cond is None) and (not col_cond in node.obj.get_text().split('\\n')[0]):\n",
    "            return content\n",
    "        content.append(get_table_column_name(node))\n",
    "        rows = node.obj.get_text().split('\\n')[1:]\n",
    "        for r in rows:\n",
    "            for m in match:\n",
    "                if m in r:\n",
    "                    content.append(r.split('|'))\n",
    "                    \n",
    "        if len(content) == 1:\n",
    "            return []\n",
    "        return content\n",
    "        \n",
    "        \n",
    "for t in tablenodes:\n",
    "    if get_table_info(t, ['营业收入（元）', '归属于上市公司股东的净利润（元）']).__len__() != 0:\n",
    "        print get_table_info(t, ['营业收入（元）', '归属于上市公司股东的净利润（元）'])\n",
    "        \n",
    "    for i in get_table_info(t, ['营业收入', '净利润'], col_cond = '变动原因'):\n",
    "        print i\n",
    "\n",
    "# for t in tablenodes:\n",
    "#     print t.obj.get_text().split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u' ', u'\\u672c\\u62a5\\u544a\\u671f ', u'\\u4e0a\\u5e74\\u540c\\u671f ',\n",
       "        u'\\u672c\\u62a5\\u544a\\u671f\\u6bd4\\u4e0a\\u5e74\\u540c\\u671f\\u589e\\u51cf '],\n",
       "       [u'\\u8425\\u4e1a\\u6536\\u5165\\uff08\\u5143\\uff09 ',\n",
       "        u'1,692,627,343.39', u' 1,231,711,694.89', u' 37.42'],\n",
       "       [ u'\\u5f52\\u5c5e\\u4e8e\\u4e0a\\u5e02\\u516c\\u53f8\\u80a1\\u4e1c\\u7684\\u51c0\\u5229\\u6da6\\uff08\\u5143\\uff09 ',\n",
       "        u'101,646,352.08', u' 66,028,042.54', u' 53.94'],\n",
       "       [ u'\\u5f52\\u5c5e\\u4e8e\\u4e0a\\u5e02\\u516c\\u53f8\\u80a1\\u4e1c\\u7684\\u6263\\u9664\\u975e\\u7ecf\\u5e38\\u6027\\u635f\\u76ca\\u7684\\u51c0\\u5229\\u6da6\\uff08\\u5143\\uff09 ',\n",
       "        u'94,316,430.2', u' 48,739,088.0', u' 93.51'],\n",
       "       [ u'\\u7ecf\\u8425\\u6d3b\\u52a8\\u4ea7\\u751f\\u7684\\u73b0\\u91d1\\u6d41\\u91cf\\u51c0\\u989d\\uff08\\u5143\\uff09 ',\n",
       "        u'82,959,884.21', u' -203,912,566.88', u' 140.68'],\n",
       "       [u'\\u57fa\\u672c\\u6bcf\\u80a1\\u6536\\u76ca\\uff08\\u5143/\\u80a1\\uff09 ',\n",
       "        u'0.03', u' 0.02', u' 50.00'],\n",
       "       [u'\\u7a00\\u91ca\\u6bcf\\u80a1\\u6536\\u76ca\\uff08\\u5143/\\u80a1\\uff09 ',\n",
       "        u'0.03', u' 0.02', u' 50.00'],\n",
       "       [u'\\u52a0\\u6743\\u5e73\\u5747\\u51c0\\u8d44\\u4ea7\\u6536\\u76ca\\u7387 ',\n",
       "        u'1.46', u' 1.00', u' 0.46'],\n",
       "       [u' ', u'\\u672c\\u62a5\\u544a\\u671f\\u672b ',\n",
       "        u'\\u4e0a\\u5e74\\u5ea6\\u672b ',\n",
       "        u'\\u672c\\u62a5\\u544a\\u671f\\u672b\\u6bd4\\u4e0a\\u5e74\\u5ea6\\u672b\\u589e\\u51cf '],\n",
       "       [u'\\u603b\\u8d44\\u4ea7\\uff08\\u5143\\uff09 ', u'18,986,094,649.97',\n",
       "        u' 19,072,275,460.82', u' -0.45'],\n",
       "       [ u'\\u5f52\\u5c5e\\u4e8e\\u4e0a\\u5e02\\u516c\\u53f8\\u80a1\\u4e1c\\u7684\\u51c0\\u8d44\\u4ea7\\uff08\\u5143\\uff09 ',\n",
       "        u'7,071,761,469.37', u' 6,882,316,207.58', u' 2.75']],\n",
       "      dtype='<U26')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "table = np.array([s.split('|') for s in get_table_nodes(nodes)[0].obj.get_text().split('\\n')])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "host = 'https://alpha-surreal.aidigger.com/api/v1/classification/intent/finance/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hd_intents = []\n",
    "all_intents = []\n",
    "for node in text_nodes:\n",
    "    content = node.obj.get_text()\n",
    "    headline = get_paragraph_headlines(node)[1][-1]\n",
    "    intents = requests.post(host,json={\"query\":content}).json()\n",
    "    head_intents = requests.post(host,json={\"query\":headline}).json()\n",
    "    for i,item in enumerate(head_intents['predict']):\n",
    "        intents['predict'][i]['prob'] += item['prob']\n",
    "    all_intents.append(intents)\n",
    "    intent = max(intents['predict'],key=lambda item:item['prob'])\n",
    "    hd_intents.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_intent(it):\n",
    "    for i,item in enumerate(it):\n",
    "        print i,item['name'],item['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_intent(all_intents[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,intent in enumerate(hd_intents):\n",
    "    print i\n",
    "    print text_nodes[i]\n",
    "    print ' ==> '.join(get_paragraph_headlines(text_nodes[i])[1])\n",
    "    print intent['name'],'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 根据芥末堆提供的意图模板，得到意图推荐的准确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = requests.post(\"https://surreal.aidigger.com/api/v1/classification/intent/finance/0\",json={ \n",
    "    \"query\": \"公司立足校园、面向家庭提供教育信息服务，深耕教育十余年已形成覆盖校内外多场景、涵盖教育主管部门、学校、教师、家长及学生等 B 端、C 端主体的业务服务体系。公司针对不同用户群体多场景、多元化需求，持续优化服务供给，逐步构建了家校互动升级业务、EdSaaS 业务、学科升学业务及继续教育业务，报告期内公司主营业务未发生变化。\"\n",
    "}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hasCN(s):\n",
    "    \"\"\"\n",
    "    判断一段文本是否有中文\n",
    "    \"\"\"\n",
    "    for ch in s.decode('utf-8'):\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataJoin = pd.read_csv('/home/zhuyuhe/mydata/jmd/percent/dataJoin.txt', delimiter='\\t', header = None)\n",
    "\n",
    "dataJoin.columns = ['文本', '意图', 'pdfurl']\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: len(x) > 30)]\n",
    "dataJoin = dataJoin[dataJoin['文本'].duplicated() == False]\n",
    "dataJoin = dataJoin[dataJoin['文本'].apply(lambda x: hasCN(x))]\n",
    "\n",
    "dataJoin.index = range(len(dataJoin))\n",
    "dataJoin['意图'] = dataJoin['意图'].apply(lambda x: intentMap(x))\n",
    "\n",
    "dataJoin = dataJoin[dataJoin['意图'].apply(lambda x: x!= 'Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in dataJoin['意图'].unique():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-27/1202791188.PDF']\n",
    "b = dataJoin[dataJoin.pdfurl == 'http://disclosure.szse.cn/finalpage/2016-10-25/1202780960.PDF'] \n",
    "c = dataJoin[dataJoin.pdfurl == 'http://www.cninfo.com.cn/finalpage/2017-04-27/1203451818.PDF']\n",
    "print a.loc[119, '文本']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(dataJoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print a['意图'].value_counts()\n",
    "print b['意图'].value_counts()\n",
    "print c['意图'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "d = {'a':1, 'b':2, 'c':3}\n",
    "sorted(d.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()[d.values().index(max(d.values()))]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [zhuEnv2]",
   "language": "python",
   "name": "Python [zhuEnv2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
